# -*- coding: utf-8 -*-
r"""
Worklog.py — Tempo → русские колонки, кликабельные ссылки, без «Сотрудник:Логин».
+ Summary (Описание) и Labels (Метки) из Jira Issue fields.
+ FTE построчно (как было) и корректный помесячный FTE в отдельном листе (monthly_fte + monthly_total).
+ Нормы рабочих дней — из производственного календаря РФ (prodcalendar), fallback — workalendar.
+ Векторная агрегация без apply (нет FutureWarning).
+ Безопасная функция HYPERLINK без f-строк.
"""

import os, re, json, time, requests, pandas as pd
from datetime import datetime, timedelta
import concurrent.futures
from pathlib import Path
from typing import Dict, Tuple, List, Optional
from calendar import monthrange

from workalendar.europe import Russia

# Optional: use official Russian production calendar if installed
try:
    import prodcalendar as prodcal  # pip install prodcalendar
    _HAS_PRODCAL = True
except Exception:
    prodcal = None
    _HAS_PRODCAL = False

from canon_utils import load_columns_map, canonize_fact, write_schema_json, norm_text, to_mmYYYY

# ========= ENV =========
JIRA_URL       = os.getenv("JIRA_URL", "").strip()
BEARER_TOKEN   = os.getenv("JIRA_TEMPO_TOKEN", "").strip()
YEAR           = int(os.getenv("YEAR", datetime.now().year))
TIMEZONE       = os.getenv("TIMEZONE", "Europe/Moscow").strip()

# Нормы: 0 -> считаем по календарю; если >0, используем фиксированные часы/месяц (например, 160)
MONTH_NORM_HOURS = float(os.getenv("MONTH_NORM_HOURS", "0"))

# Точечные переопределения нормы рабочих дней: "YYYY-MM=18;YYYY-MM=21"
MONTH_NORM_OVERRIDE = os.getenv("MONTH_NORM_OVERRIDE", "")

# Использовать производственный календарь РФ (prodcalendar) при наличии
USE_PRODUCTION_CALENDAR = os.getenv("USE_PRODUCTION_CALENDAR", "1") == "1"

if not JIRA_URL or not BEARER_TOKEN:
    raise SystemExit("ENV JIRA_URL или JIRA_TEMPO_TOKEN не заданы")

FILL_ACCOUNT_ENABLED  = os.getenv("FILL_ACCOUNT_ENABLED", "1") == "1"
FILL_ACCOUNT_PROJECTS = [p.strip() for p in os.getenv("FILL_ACCOUNT_PROJECTS", "INT").split(";") if p.strip()]
FILL_ACCOUNT_PREFIX   = os.getenv("FILL_ACCOUNT_PREFIX", "INT: ")
EXCEL_AUTOFIT         = os.getenv("EXCEL_AUTOFIT", "1") == "1"  # умный автофит

WL_DIR     = Path(r"C:\Users\zaytsev_ra2\PycharmProjects\TCO\WL")
WL_OUT_DIR = WL_DIR / "Результат"

# ====== Rates directory config ======
RATES_FOLDER  = Path(r"C:\Users\zaytsev_ra2\PycharmProjects\Контроль бюджета\Ставки")
RATES_PATTERN = "employee_rate_directory_*.xlsx"  # mask for the rates files

# ================= helpers for rates =================
def _pick_latest_file(folder: Path, pattern: str) -> Optional[Path]:
    files = sorted(Path(folder).glob(pattern), key=lambda p: p.stat().st_mtime, reverse=True)
    return files[0] if files else None

def _pick_col(df: pd.DataFrame, candidates):
    low = {c.lower(): c for c in df.columns}
    for cand in candidates:
        cl = cand.strip().lower()
        if cl in low:
            return low[cl]
    for cand in candidates:
        cl = cand.strip().lower()
        for c in df.columns:
            if cl in c.strip().lower():
                return c
    return None

def normalize_employee_name(name: str) -> str:
    if name is None:
        return ""
    s = str(name)
    s = s.replace("\u00a0", " ").replace("\u202f", " ")
    s = re.sub(r'\s*(\[[^\]]+\]\s*)+$', '', s).strip()
    s = re.sub(r'\s+', ' ', s)
    return s

def load_rate_directory_or_none(folder: Path, pattern: str) -> Optional[pd.DataFrame]:
    path = _pick_latest_file(folder, pattern)
    if path is None:
        print(f"[RATES] Нет файлов в '{folder}' по маске '{pattern}' — пропускаю ставки.")
        return None
    try:
        rdf = pd.read_excel(path)
    except Exception as e:
        print(f"[RATES] Ошибка чтения '{path}': {e} — пропускаю ставки.")
        return None
    emp  = _pick_col(rdf, ["Сотрудник","ФИО","Сотрудник ФИО"])
    rate = _pick_col(rdf, ["Ставка","Ставка, ₽/ч","Ставка (₽/ч)","Стоимость часа","Цена часа"])
    cc   = _pick_col(rdf, ["Сотрудник:ЦК","ЦК","Cost Center","СЦК"])
    dept = _pick_col(rdf, ["Сотрудник:Направление","Направление","Отдел","Департамент"])
    cat  = _pick_col(rdf, ["Сотрудник:Категория","Категория сотрудника","Категория"])
    if not emp or not rate:
        print(f"[RATES] В '{path.name}' нет обязательных колонок (Сотрудник/Ставка) — пропускаю ставки.")
        return None
    rename = {emp:"Сотрудник", rate:"Ставка"}
    if cc:   rename[cc]   = "Сотрудник:ЦК"
    if dept: rename[dept] = "Сотрудник:Направление"
    if cat:  rename[cat]  = "Сотрудник:Категория"
    rdf = rdf.rename(columns=rename)
    rdf["Ставка"] = pd.to_numeric(rdf["Ставка"], errors="coerce")
    rdf["Сотрудник_norm"] = rdf["Сотрудник"].apply(normalize_employee_name)
    keep = [c for c in ["Сотрудник","Ставка","Сотрудник:ЦК","Сотрудник:Направление","Сотрудник:Категория","Сотрудник_norm"] if c in rdf.columns]
    rdf = rdf[keep].dropna(subset=["Сотрудник_norm"]).drop_duplicates(subset=["Сотрудник_norm"])
    print(f"[RATES] Загружен справочник '{path.name}': {len(rdf)} сотрудников")
    return rdf

def enrich_with_rates(df: pd.DataFrame, rates: Optional[pd.DataFrame]) -> pd.DataFrame:
    if rates is None or rates.empty:
        return df
    if "Сотрудник" not in df.columns:
        emp = _pick_col(df, ["Сотрудник","ФИО","Сотрудник ФИО"])
        if not emp:
            print("[RATES] Нет колонки 'Сотрудник' — пропускаю ставки.")
            return df
        if emp != "Сотрудник":
            df = df.rename(columns={emp:"Сотрудник"})
    df["Сотрудник_norm"] = df["Сотрудник"].apply(normalize_employee_name)
    if "Сотрудник_norm" not in rates.columns:
        rates["Сотрудник_norm"] = rates["Сотрудник"].apply(normalize_employee_name)
    merged = df.merge(rates, on="Сотрудник_norm", how="left", suffixes=("", "_rate"))
    if "Ставка, ₽/ч" in merged.columns and "Ставка" not in merged.columns:
        merged = merged.rename(columns={"Ставка, ₽/ч": "Ставка"})
    hours_col = _pick_col(merged, ["Часы факт","Часы","Hours","Время, ч"])
    if hours_col:
        rate_col = "Ставка" if "Ставка" in merged.columns else ("Ставка, ₽/ч" if "Ставка, ₽/ч" in merged.columns else None)
        if rate_col:
            merged["Стоимость, ₽"] = (merged[hours_col].fillna(0) * merged[rate_col].fillna(0)).round(2)
    if "Ставка, ₽/ч" in merged.columns and "Ставка" in merged.columns:
        merged = merged.drop(columns=["Ставка, ₽/ч"])
    for c in ["Сотрудник_rate","Сотрудник_norm"]:
        if c in merged.columns:
            merged = merged.drop(columns=[c])
    return merged

# ====== Final column order helper ======
FINAL_ORDER = ["Тип задачи", "Ссылка на задачу", "Описание", "Метки", "Проект", "Сервис", "Месяц",
               "Сотрудник", "Сотрудник:Категория", "Сотрудник:ЦК", "Сотрудник:Направление",
               "Тип активности", "Часы факт", "FTE факт", "Ставка", "Стоимость, ₽"]

def reorder_final(df: pd.DataFrame) -> pd.DataFrame:
    keep = [c for c in FINAL_ORDER if c in df.columns]
    rest = [c for c in df.columns if c not in keep]
    return df[keep + rest]

# ============================================
WL_OUT_DIR.mkdir(parents=True, exist_ok=True)
COLUMNS_MAP_PATH = Path(__file__).with_name("columns_map.json")

HEADERS = {
    "Authorization": f"Bearer {BEARER_TOKEN}",
    "Content-Type": "application/json",
    "Accept": "application/json"
}

# ========= Умный автофит =========
WIDTH_OVERRIDES = {"Ссылка на задачу": 16, "Сервис": 34, "Описание": 60}
CLAMP_MIN, CLAMP_MAX = 6, 60

def _visible_text(cell_val):
    if not isinstance(cell_val, str):
        return "" if cell_val is None else str(cell_val)
    s = cell_val.strip()
    if not s.startswith("="):
        return s
    m = re.match(r'^\s*=\s*HYPERLINK\s*\(\s*"[^"]*"\s*[,;]\s*"([^"]*)"\s*\)\s*$', s, re.IGNORECASE)
    return m.group(1) if m else s

def excel_autofit_smart(path: Path):
    try:
        from openpyxl import load_workbook
        wb = load_workbook(path)
        for ws in wb.worksheets:
            headers = {cell.column: (cell.value or "") for cell in ws[1]}
            for col in ws.columns:
                col_idx = col[0].column
                head = str(headers.get(col_idx, "")).strip()
                if head in WIDTH_OVERRIDES:
                    ws.column_dimensions[col[0].column_letter].width = WIDTH_OVERRIDES[head]
                    continue
                max_len = max(len(_visible_text(c.value)) for c in col)
                max_len = max(max_len, len(head))
                ws.column_dimensions[col[0].column_letter].width = max(CLAMP_MIN, min(max_len + 2, CLAMP_MAX))
        wb.save(path)
    except Exception as e:
        print(f"[autofit] пропущено: {e}")

# ========= misc helpers =========
def load_json(path: Path) -> Dict[str, str]:
    if path.exists():
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception:
            return {}
    return {}

def save_json(path: Path, data: Dict[str, str]):
    try:
        with open(path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False)
    except Exception as e:
        print(f"[cache] не удалось сохранить {path.name}: {e}")

def get_display_name(wid: str) -> Tuple[str, str]:
    url = f"{JIRA_URL}/rest/api/2/user?key={wid}"
    try:
        r = requests.get(url, headers=HEADERS, timeout=10)
        if r.status_code == 200:
            user = r.json()
            return wid, user.get("displayName", wid)
    except Exception:
        time.sleep(0.2)
    return wid, wid

def fetch_issue_summary_labels(issue_key: str) -> Tuple[str, Dict[str, str]]:
    url = f"{JIRA_URL}/rest/api/2/issue/{issue_key}?fields=summary,labels"
    try:
        r = requests.get(url, headers=HEADERS, timeout=10)
        if r.status_code == 200:
            data = r.json() or {}
            fields = data.get("fields") or {}
            return issue_key, {
                "summary": fields.get("summary", "") or "",
                "labels": ",".join(fields.get("labels") or [])
            }
    except Exception:
        time.sleep(0.2)
    return issue_key, {"summary": "", "labels": ""}

def sanitize_for_account(title: str) -> str:
    if title is None:
        return ""
    s = " ".join(str(title).replace("\n", " ").replace("\r", " ").split())
    return s[:100]

def hyperlink_formula(jira_base_url: str, key: str) -> str:
    """Возвращает формулу Excel HYPERLINK без f-строк (устраняет SyntaxError на некоторых сборках).
    Дублируем кавычки для Excel: " → "".
    """
    if not key:
        return ""
    k = str(key).strip().replace('"', '""')
    base = str(jira_base_url).rstrip('/')
    return '=HYPERLINK("{}", "{}")'.format("{}/browse/{}".format(base, k), k)

# ========= Нормы рабочего времени =========
def _iter_month_dates(year: int, month: int):
    days = monthrange(year, month)[1]
    for d in range(1, days + 1):
        yield datetime(year, month, d).date()

def build_month_norms(year: int) -> Dict[str, int]:
    """
    Возвращает нормы РАБОЧИХ ДНЕЙ по месяцам (YYYY-MM -> int).
    Приоритеты:
    1) prodcalendar (официальный производственный календарь РФ), если установлен и USE_PRODUCTION_CALENDAR=1
    2) workalendar.europe.Russia (как fallback)
    3) Переопределения через MONTH_NORM_OVERRIDE применяются поверх любого источника
    """
    norms: Dict[str, int] = {}

    if USE_PRODUCTION_CALENDAR and _HAS_PRODCAL:
        # prodcalendar: учитывает переносы и рабочие субботы
        for m in range(1, 13):
            cnt = 0
            for dt in _iter_month_dates(year, m):
                try:
                    if prodcal.is_working_day(dt):
                        cnt += 1
                except Exception:
                    if dt.weekday() < 5:
                        cnt += 1
            norms["{}-{:02d}".format(year, m)] = cnt
    else:
        # Fallback: workalendar
        cal = Russia()
        for m in range(1, 13):
            start = datetime(year, m, 1)
            end = (datetime(year, m+1, 1) - timedelta(days=1)) if m < 12 else datetime(year, 12, 31)
            norms["{}-{:02d}".format(year, m)] = int(cal.get_working_days_delta(start.date(), end.date()))

    # Точечные переопределения из ENV применяются в конце
    if MONTH_NORM_OVERRIDE:
        for part in MONTH_NORM_OVERRIDE.split(";"):
            part = part.strip()
            if not part or "=" not in part:
                continue
            ym, val = part.split("=", 1)
            ym, val = ym.strip(), val.strip()
            try:
                norms[ym] = int(val)
            except:
                pass
    return norms

month_norms = build_month_norms(YEAR)

def month_norm_days(ym: str) -> int:
    # ym = "YYYY-MM"
    return int(month_norms.get(ym, 20))

# ========= 1) Tempo =========
tempo_url = f"{JIRA_URL}/rest/tempo-timesheets/4/worklogs/search"
payload = {"from": f"{YEAR}-01-01", "to": f"{YEAR}-12-31"}
resp = requests.post(tempo_url, json=payload, headers=HEADERS, timeout=120)
if resp.status_code != 200:
    print("Ошибка запроса к Tempo:", resp.status_code, resp.text); raise SystemExit(1)
worklogs = resp.json() or []

# ========= 2) Кеш пользователей =========
worker_ids = list({w.get("worker") for w in worklogs if w.get("worker")})
worker_map_path = WL_DIR / 'worker_map.json'
worker_map = load_json(worker_map_path)
new_ids = [wid for wid in worker_ids if wid and wid not in worker_map]
if new_ids:
    print(f"Новых пользователей: {len(new_ids)} — обновляем кэш...")
    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as ex:
        for wid, name in ex.map(get_display_name, new_ids):
            worker_map[wid] = name
    save_json(worker_map_path, worker_map)

# ========= 3) Кеш summary+labels =========
summary_labels_cache_path = WL_DIR / "issue_summary_labels_cache.json"
summary_labels_cache = load_json(summary_labels_cache_path)

all_issue_keys = sorted({(w.get("issue") or {}).get("key") for w in worklogs if (w.get("issue") or {}).get("key")})
need_keys_sl = [k for k in all_issue_keys if k and k not in summary_labels_cache]
if need_keys_sl:
    print(f"Новых issues для summary+labels: {len(need_keys_sl)}")
    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as ex:
        for ikey, data in ex.map(fetch_issue_summary_labels, need_keys_sl):
            summary_labels_cache[ikey] = data
    save_json(summary_labels_cache_path, summary_labels_cache)

# ========= 4) Формирование строк =========
rows = []
filled_cnt = 0

# Функция безопасного парсинга даты с TZ нормализацией:
def parse_started_ts(value) -> Optional[datetime]:
    """
    Преобразует Tempo started → локальное наивное время в заданном TIMEZONE.
    Устраняет утечки в соседние месяцы из-за TZ.
    """
    try:
        ts = pd.to_datetime(value, utc=True, errors="coerce")
        if pd.isna(ts):
            return None
        ts = ts.tz_convert(TIMEZONE).tz_localize(None)
        return ts.to_pydatetime()
    except Exception:
        return None

for w in worklogs:
    issue = w.get("issue") or {}
    attrs = w.get("attributes") or {}
    activity_type = (attrs.get("_Типактивности_", {}) or {}).get("value")

    started_dt = parse_started_ts(w.get("started"))
    ym = started_dt.strftime("%Y-%m") if started_dt else None
    mmYYYY = started_dt.strftime("%m/%Y") if started_dt else None

    hours = (w.get("timeSpentSeconds") or 0) / 3600.0
    # Построчный FTE (для информации; для отчёта по месяцу используем агрегированный расчёт ниже)
    if MONTH_NORM_HOURS > 0:
        fte = hours / MONTH_NORM_HOURS
    else:
        days_norm = month_norm_days(ym) if ym else 20
        fte = (hours / 8.0) / days_norm if days_norm else None

    issue_key   = (issue.get("key") or "").strip()
    project_key = issue.get("projectKey")
    issue_type  = issue.get("issueType")
    account_key = issue.get("accountKey")

    # Summary/Labels из кэша
    sl = summary_labels_cache.get(issue_key) or {"summary": "", "labels": ""}
    summary_for_report = sl.get("summary", "") or ""
    labels_for_report  = sl.get("labels", "") or ""

    if FILL_ACCOUNT_ENABLED and project_key in FILL_ACCOUNT_PROJECTS and not str(account_key or "").strip():
        smry = summary_for_report or issue_key
        account_key = f"{FILL_ACCOUNT_PREFIX}{sanitize_for_account(smry)}" if FILL_ACCOUNT_PREFIX else sanitize_for_account(smry)
        filled_cnt += 1

    rows.append({
        "IssueKey_tmp": issue_key,                 # для ссылки (не попадёт в итог)
        "Worker Name":  worker_map.get(w.get("worker"), w.get("worker")),
        "Account Key":  account_key,
        "Project Key":  project_key,
        "Issue Type":   issue_type,
        "Activity Type":activity_type,
        "Started (mm/yyyy)": mmYYYY,
        "Time Spent (h)": round(hours, 2),
        "FTE":                round(fte, 3) if fte is not None else None,
        "Summary":            summary_for_report,
        "Labels":             labels_for_report,
        "_ym":                ym,                 # для агрегации
    })

print(f"Автозаполнение Account Key из summary: {filled_cnt} задач.")

df = pd.DataFrame(rows)

# ========= 5) Русские названия + порядок + ссылка =========
df.insert(0, "Ссылка на задачу", df["IssueKey_tmp"].map(lambda k: hyperlink_formula(JIRA_URL, k)))
df.drop(columns=["IssueKey_tmp"], inplace=True)

df.rename(columns={
    "Worker Name":        "Сотрудник",
    "Account Key":        "Сервис",
    "Project Key":        "Проект",
    "Issue Type":         "Тип задачи",
    "Activity Type":      "Тип активности",
    "Started (mm/yyyy)":  "Месяц",
    "Time Spent (h)":     "Часы факт",
    "FTE":                "FTE факт",
    "Summary":            "Описание",
    "Labels":             "Метки",
}, inplace=True)

RU_ORDER = ["Тип задачи","Ссылка на задачу","Описание","Метки","Проект","Сервис","Месяц",
            "Сотрудник","Сотрудник:Категория","Сотрудник:ЦК","Сотрудник:Направление",
            "Тип активности","Часы факт","FTE факт","Ставка","Стоимость, ₽"]

df = df[[c for c in RU_ORDER if c in df.columns] + [c for c in df.columns if c not in RU_ORDER]]

# ====== RATES ENRICHMENT ======
try:
    _rates_df = load_rate_directory_or_none(RATES_FOLDER, RATES_PATTERN)
    df = enrich_with_rates(df, _rates_df)
    df = reorder_final(df)
except Exception as _e:
    print(f"[RATES] Ошибка обогащения ставками: {_e}")

# ========= 6) Векторная агрегация FTE =========
# Приводим технический ключ месяца
if "_ym" not in df.columns:
    df["_ym"] = pd.to_datetime(df["Месяц"], format="%m/%Y", errors="coerce").dt.strftime("%Y-%m")

# 1) FTE по месяцу и сотруднику
monthly = (
    df.groupby(["_ym", "Сотрудник"], dropna=False)["Часы факт"]
      .sum()
      .reset_index()
      .rename(columns={"_ym": "Месяц (YYYY-MM)"})
)

if MONTH_NORM_HOURS > 0:
    monthly["Норма_дней"]  = None
    monthly["Норма_часов"] = MONTH_NORM_HOURS
    monthly["FTE месяц"]   = (monthly["Часы факт"] / MONTH_NORM_HOURS).round(3)
else:
    monthly["Норма_дней"]  = monthly["Месяц (YYYY-MM)"].map(month_norm_days).astype("Int64")
    monthly["Норма_часов"] = (8 * monthly["Норма_дней"]).astype("Int64")
    monthly["FTE месяц"]   = (monthly["Часы факт"] / monthly["Норма_часов"]).round(3)

# 2) Итог по месяцу (все сотрудники)
monthly_total = (
    monthly.groupby(["Месяц (YYYY-MM)"])["Часы факт"]
           .sum()
           .reset_index()
)

if MONTH_NORM_HOURS > 0:
    monthly_total["Норма_дней"]  = None
    monthly_total["Норма_часов"] = MONTH_NORM_HOURS
    monthly_total["FTE месяц (итого)"] = (monthly_total["Часы факт"] / MONTH_NORM_HOURS).round(3)
else:
    monthly_total["Норма_дней"]  = monthly_total["Месяц (YYYY-MM)"].map(month_norm_days).astype("Int64")
    monthly_total["Норма_часов"] = (8 * monthly_total["Норма_дней"]).astype("Int64")
    monthly_total["FTE месяц (итого)"] = (monthly_total["Часы факт"] / monthly_total["Норма_часов"]).round(3)

# ========= 7) RAW Excel =========
stamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
raw_path = WL_DIR / f"worklogs_{stamp}.xlsx"
with pd.ExcelWriter(raw_path, engine="openpyxl") as w:
    df.to_excel(w, index=False, sheet_name="worklogs_raw")
    monthly.to_excel(w, index=False, sheet_name="monthly_fte")
    monthly_total.to_excel(w, index=False, sheet_name="monthly_total")
if EXCEL_AUTOFIT:
    excel_autofit_smart(raw_path)
print(f"✅ RAW: {raw_path}")

# ========= 8) Canonical =========
columns_map = load_columns_map(COLUMNS_MAP_PATH)
df_can, canon_log = canonize_fact(df, columns_map, coerce_types=True)
# финальная нормализация
if "Месяц" in df_can.columns:     df_can["Месяц"] = df_can["Месяц"].map(to_mmYYYY)
if "Сотрудник" in df_can.columns: df_can["Сотрудник"] = df_can["Сотрудник"].map(norm_text)
if "Сервис" in df_can.columns:    df_can["Сервис"] = df_can["Сервис"].map(norm_text)
if "Сотрудник:Логин" in df_can.columns:
    df_can.drop(columns=["Сотрудник:Логин"], inplace=True, errors="ignore")
df_can = df_can[[c for c in RU_ORDER if c in df_can.columns] + [c for c in df_can.columns if c not in RU_ORDER]]

can_path = WL_OUT_DIR / f"worklogs_canonical_{stamp}.xlsx"
with pd.ExcelWriter(can_path, engine="openpyxl") as w:
    df_can.to_excel(w, index=False, sheet_name="worklogs")
    monthly.to_excel(w, index=False, sheet_name="monthly_fte")
    monthly_total.to_excel(w, index=False, sheet_name="monthly_total")
    if not canon_log.empty:
        canon_log.to_excel(w, index=False, sheet_name="canonical_log")
if EXCEL_AUTOFIT:
    excel_autofit_smart(can_path)

write_schema_json(can_path.with_suffix(".schema.json"), {"worklogs": df_can, "monthly_fte": monthly, "monthly_total": monthly_total})
print(f"✅ Canonical: {can_path}")
print(f"🧾 Schema:    {can_path.with_suffix('.schema.json')}")

# ========= 9) Диагностика =========
try:
    ym_check = f"{YEAR}-05"
    may_hours_total = float(monthly_total.loc[monthly_total["Месяц (YYYY-MM)"].eq(ym_check), "Часы факт"].sum())
    if MONTH_NORM_HOURS > 0:
        denom = MONTH_NORM_HOURS
    else:
        denom = 8 * month_norm_days(ym_check)
    if denom:
        print(f"[CHECK] МАЙ {YEAR}: Σчасы={may_hours_total}, знаменатель={denom}, ожидаемый FTE={may_hours_total/denom:.3f}")
    print(f"[CHECK] Источник норм: {'prodcalendar' if (USE_PRODUCTION_CALENDAR and _HAS_PRODCAL) else 'workalendar'}; override='{MONTH_NORM_OVERRIDE}'")
except Exception as e:
    print(f"[CHECK] Ошибка диагностики мая: {e}")
