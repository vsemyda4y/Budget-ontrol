# -*- coding: utf-8 -*-
r"""
main.py ‚Äî –≤—ã–≥—Ä—É–∑–∫–∞ worklogs –∏–∑ Jira Tempo –∑–∞ –≥–æ–¥ + –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å–∏—Å—Ç–µ–º–æ–π –º–∞–ø–ø–∏–Ω–≥–∞ –∫–æ–ª–æ–Ω–æ–∫.
–°–æ—Ö—Ä–∞–Ω—è–µ—Ç:
  1) –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π Excel –≤ –ø–∞–ø–∫—É WL (–∫–∞–∫ —Ä–∞–Ω—å—à–µ).
  2) –ö–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–π Excel + canonical_log + schema.json –≤ WL\–†–µ–∑—É–ª—å—Ç–∞—Ç.
"""

import os
import json
import time
import requests
import pandas as pd
from workalendar.europe import Russia
from datetime import datetime
import concurrent.futures
from openpyxl import load_workbook
from pathlib import Path
import numpy as np

# === –ö–æ–Ω—Ñ–∏–≥ (–º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —á–µ—Ä–µ–∑ ENV) ===
JIRA_URL     = os.getenv("JIRA_URL", "https://jira.nlmk.com")
BEARER_TOKEN = os.getenv("JIRA_TEMPO_TOKEN", "MzU0MzcxNjA3NDc2Orij/u46oRiprLkwp1B7r55Yx7bE")
YEAR         = int(os.getenv("YEAR", "2025"))

# –ü—É—Ç–∏
WL_DIR         = Path(r"C:\Users\zaytsev_ra2\PycharmProjects\TCO\Data\Worklog")
WL_OUT_DIR     = WL_DIR / "–†–µ–∑—É–ª—å—Ç–∞—Ç"
WL_OUT_DIR.mkdir(parents=True, exist_ok=True)

# === –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å–∏—Å—Ç–µ–º–æ–π –º–∞–ø–ø–∏–Ω–≥–∞ ===
# –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ —Ä—è–¥–æ–º —Å–æ —Å–∫—Ä–∏–ø—Ç–æ–º –ª–µ–∂–∞—Ç canon_utils.py –∏ columns_map.json
from canon_utils import (
    load_columns_map, canonize_fact, write_schema_json,
    norm_text, to_mmYYYY
)
COLUMNS_MAP_PATH = Path(__file__).with_name("columns_map.json")

HEADERS = {
    "Authorization": f"Bearer {BEARER_TOKEN}",
    "Content-Type": "application/json",
    "Accept": "application/json"
}

# === –ó–∞–ø—Ä–æ—Å –∫ Tempo: –≤—Å–µ worklogs –∑–∞ –≥–æ–¥ ===
tempo_url = f"{JIRA_URL}/rest/tempo-timesheets/4/worklogs/search"
payload = {
    "from": f"{YEAR}-01-01",
    "to": f"{YEAR}-12-31"
}

response = requests.post(tempo_url, json=payload, headers=HEADERS, timeout=120)
if response.status_code != 200:
    print("–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ Tempo:", response.status_code, response.text)
    raise SystemExit(1)

worklogs = response.json() or []

# === –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –§–ò–û –ø–æ worker id ===
def get_display_name(wid: str):
    user_url = f"{JIRA_URL}/rest/api/2/user?key={wid}"
    try:
        r = requests.get(user_url, headers=HEADERS, timeout=10)
        if r.status_code == 200:
            user_data = r.json()
            return wid, user_data.get("displayName", wid)
        else:
            return wid, wid
    except Exception:
        time.sleep(0.2)
        return wid, wid

# === –ö–µ—à –º–∞–ø–ø–∏–Ω–≥–∞ JIRAUSER ‚Üí –§–ò–û ===
worker_ids = list({w.get("worker") for w in worklogs if w.get("worker")})
cache_file = WL_DIR / 'worker_map.json'

if cache_file.exists():
    with open(cache_file, 'r', encoding='utf-8') as f:
        worker_map = json.load(f)
    new_ids = [wid for wid in worker_ids if wid not in worker_map]
    if new_ids:
        print(f"–ù–∞–π–¥–µ–Ω–æ –Ω–æ–≤—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {len(new_ids)} ‚Äî –æ–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à...")
        with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:
            for wid, name in executor.map(get_display_name, new_ids):
                worker_map[wid] = name
        with open(cache_file, 'w', encoding='utf-8') as f:
            json.dump(worker_map, f, ensure_ascii=False)
else:
    print(f"–ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ ‚Äî —Å–æ–∑–¥–∞—ë–º –∫—ç—à –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π ({len(worker_ids)})...")
    worker_map = {}
    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:
        for wid, name in executor.map(get_display_name, worker_ids):
            worker_map[wid] = name
    with open(cache_file, 'w', encoding='utf-8') as f:
        json.dump(worker_map, f, ensure_ascii=False)

# === –ö–∞–ª–µ–Ω–¥–∞—Ä—å —Ä–∞–±–æ—á–∏—Ö –¥–Ω–µ–π –ø–æ –º–µ—Å—è—Ü–∞–º (–†–æ—Å—Å–∏—è) ===
cal = Russia()
month_norms = {}
for month in range(1, 13):
    start = datetime(YEAR, month, 1)
    end = (datetime(YEAR, month + 1, 1) - pd.Timedelta(days=1)) if month < 12 else datetime(YEAR, 12, 31)
    norm = cal.get_working_days_delta(start.date(), end.date())
    month_norms[f"{YEAR}-{month:02d}"] = norm

# === –§–æ—Ä–º–∏—Ä—É–µ–º "—Å—ã—Ä–æ–π" –¥–∞—Ç–∞—Ñ—Ä–µ–π–º –∫–∞–∫ —Ä–∞–Ω—å—à–µ ===
rows = []
for w in worklogs:
    issue = w.get("issue", {}) or {}
    attributes = w.get("attributes", {}) or {}
    activity_type = (attributes.get("_–¢–∏–ø–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏_", {}) or {}).get("value")

    started_raw = w.get("started")
    started_date = pd.to_datetime(started_raw, errors="coerce")
    started_month = started_date.strftime("%Y-%m") if pd.notnull(started_date) else None
    started_mm_yyyy = started_date.strftime("%m/%Y") if pd.notnull(started_date) else None

    workdays_in_month = month_norms.get(started_month, 20)

    seconds = w.get("timeSpentSeconds") or 0
    hours = seconds / 3600.0
    days = hours / 8.0
    fte = (days / workdays_in_month) if workdays_in_month else None

    rows.append({
        "Issue Key": issue.get("key"),
        "Project Key": issue.get("projectKey"),
        "Issue Type": issue.get("issueType"),
        "Account Key": issue.get("accountKey"),
        "Worker Name": worker_map.get(w.get("worker"), w.get("worker")),
        "Time Spent (h)": round(hours, 2),
        "Activity Type": activity_type,
        "Started (mm/yyyy)": started_mm_yyyy,
        "FTE": round(fte, 3) if fte is not None else None
    })

df = pd.DataFrame(rows)

# === –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª (–∫–∞–∫ —Ä–∞–Ω—å—à–µ) –≤ WL ===
WL_DIR.mkdir(parents=True, exist_ok=True)
file_name_raw = f"worklogs_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.xlsx"
file_path_raw = WL_DIR / file_name_raw

df.to_excel(file_path_raw, index=False)

# –∞–≤—Ç–æ—à–∏—Ä–∏–Ω–∞
wb = load_workbook(file_path_raw)
ws = wb.active
for col in ws.columns:
    max_length = 0
    col_letter = col[0].column_letter
    for cell in col:
        try:
            if cell.value:
                max_length = max(max_length, len(str(cell.value)))
        except Exception:
            pass
    ws.column_dimensions[col_letter].width = min(max_length + 2, 80)
wb.save(file_path_raw)

print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã (RAW): {file_path_raw}")

# === –ö–ê–ù–û–ù–ò–ó–ê–¶–ò–Ø –ü–û –ù–ê–®–ï–ô –°–ò–°–¢–ï–ú–ï –ú–ê–ü–ü–ò–ù–ì–ê ===
columns_map = load_columns_map(COLUMNS_MAP_PATH)

# –ø–µ—Ä–µ–∏–º–µ–Ω—É–µ–º —Å—Ç–æ–ª–±—Ü—ã –≤ –∫–∞–Ω–æ–Ω—ã (–°–æ—Ç—Ä—É–¥–Ω–∏–∫, –°–µ—Ä–≤–∏—Å, –ú–µ—Å—è—Ü, FTE —Ñ–∞–∫—Ç, –ß–∞—Å—ã —Ñ–∞–∫—Ç, ‚Ä¶)
df_can, canon_log = canonize_fact(df, columns_map, coerce_types=True)

# –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª—é—á–µ–≤—ã—Ö –ø–æ–ª–µ–π –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
if "–ú–µ—Å—è—Ü" in df_can.columns:
    df_can["–ú–µ—Å—è—Ü"] = df_can["–ú–µ—Å—è—Ü"].map(to_mmYYYY)
if "–°–æ—Ç—Ä—É–¥–Ω–∏–∫" in df_can.columns:
    df_can["–°–æ—Ç—Ä—É–¥–Ω–∏–∫"] = df_can["–°–æ—Ç—Ä—É–¥–Ω–∏–∫"].map(norm_text)
if "–°–µ—Ä–≤–∏—Å" in df_can.columns:
    df_can["–°–µ—Ä–≤–∏—Å"] = df_can["–°–µ—Ä–≤–∏—Å"].map(norm_text)

# –µ—Å–ª–∏ –Ω–µ –æ–∫–∞–∑–∞–ª–æ—Å—å FTE —Ñ–∞–∫—Ç ‚Äî —Å—á–∏—Ç–∞–µ–º –∏–∑ —á–∞—Å–æ–≤ (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
if "FTE —Ñ–∞–∫—Ç" not in df_can.columns or df_can["FTE —Ñ–∞–∫—Ç"].dropna().empty:
    if "–ß–∞—Å—ã —Ñ–∞–∫—Ç" in df_can.columns:
        df_can["FTE —Ñ–∞–∫—Ç"] = pd.to_numeric(df_can["–ß–∞—Å—ã —Ñ–∞–∫—Ç"], errors="coerce") / 160.0
    elif "Time Spent (h)" in df.columns:
        df_can["FTE —Ñ–∞–∫—Ç"] = pd.to_numeric(df["Time Spent (h)"], errors="coerce") / 160.0
    else:
        # –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å ‚Äî –ø–ª–∞–Ω_vs_fact –ø—Ä–µ–¥—É–ø—Ä–µ–¥–∏—Ç, –µ—Å–ª–∏ FTE —Ñ–∞–∫—Ç –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω
        pass

# === –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–π —Ñ–∞–π–ª –≤ WL\–†–µ–∑—É–ª—å—Ç–∞—Ç ===
stamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
file_name_can = f"worklogs_canonical_{stamp}.xlsx"
file_path_can = WL_OUT_DIR / file_name_can

with pd.ExcelWriter(file_path_can, engine="openpyxl") as w:
    df_can.to_excel(w, index=False, sheet_name="worklogs")
    if not canon_log.empty:
        canon_log.to_excel(w, index=False, sheet_name="canonical_log")

# –∞–≤—Ç–æ—à–∏—Ä–∏–Ω–∞
try:
    wb = load_workbook(file_path_can)
    for ws in wb.worksheets:
        for col in ws.columns:
            max_length = 0
            col_letter = col[0].column_letter
            for cell in col:
                try:
                    if cell.value:
                        max_length = max(max_length, len(str(cell.value)))
                except Exception:
                    pass
            ws.column_dimensions[col_letter].width = min(max_length + 2, 80)
    wb.save(file_path_can)
except Exception as e:
    print(f"–ê–≤—Ç–æ—à–∏—Ä–∏–Ω–∞ –¥–ª—è –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–æ–≥–æ —Ñ–∞–π–ª–∞ –ø—Ä–æ–ø—É—â–µ–Ω–∞: {e}")

# —Å—Ö–µ–º–∞ –¥–ª—è canonical
schema_path = file_path_can.with_suffix(".schema.json")
write_schema_json(schema_path, {"worklogs": df_can})

print(f"‚úÖ –ö–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–π —Ñ–∞–π–ª: {file_path_can}")
print(f"üßæ –°—Ö–µ–º–∞:            {schema_path}")
