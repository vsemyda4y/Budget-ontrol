# -*- coding: utf-8 -*-
r"""
Worklog.py — Tempo → русские колонки, кликабельные ссылки, без «Сотрудник:Логин».
+ Summary (Описание) и Labels (Метки) из Jira Issue fields.
+ FTE построчно и корректный помесячный FTE (monthly_fte + monthly_total).
+ ВРЕМЕННО: нормы рабочих дней зашиты для 2025 года строго по производственному календарю РФ.
+ Векторная агрегация (без GroupBy.apply и без FutureWarning).
+ Безопасная функция Excel HYPERLINK (без f-строк).
"""

import os, re, json, time, requests, pandas as pd
from datetime import datetime, timedelta, date
import concurrent.futures
from pathlib import Path
from typing import Dict, Tuple, Optional

# === canon utils (ваши вспомогательные) ===
from canon_utils import load_columns_map, canonize_fact, write_schema_json, norm_text, to_mmYYYY

# ========= ENV =========
JIRA_URL     = os.getenv("JIRA_URL", "").strip()
BEARER_TOKEN = os.getenv("JIRA_TEMPO_TOKEN", "").strip()

# Окно выгрузки из Tempo (только для запроса; на расчёт FTE не влияет)
_today = date.today()
FROM_DATE = os.getenv("FROM_DATE", f"{_today.year}-01-01")
TO_DATE   = os.getenv("TO_DATE",   f"{_today.year}-12-31")

TIMEZONE = os.getenv("TIMEZONE", "Europe/Moscow").strip()
EXCEL_AUTOFIT = os.getenv("EXCEL_AUTOFIT", "1") == "1"

# (опционально) Автозаполнение Account Key по summary для проектов из списка
FILL_ACCOUNT_ENABLED  = os.getenv("FILL_ACCOUNT_ENABLED", "1") == "1"
FILL_ACCOUNT_PROJECTS = [p.strip() for p in os.getenv("FILL_ACCOUNT_PROJECTS", "INT").split(";") if p.strip()]
FILL_ACCOUNT_PREFIX   = os.getenv("FILL_ACCOUNT_PREFIX", "INT: ")

if not JIRA_URL or not BEARER_TOKEN:
    raise SystemExit("ENV JIRA_URL или JIRA_TEMPO_TOKEN не заданы")

# ========= Папки =========
WL_DIR     = Path(r"C:\Users\zaytsev_ra2\PycharmProjects\TCO\WL")
WL_OUT_DIR = WL_DIR / "Результат"
WL_OUT_DIR.mkdir(parents=True, exist_ok=True)

# ====== Rates directory config ======
RATES_FOLDER  = Path(r"C:\Users\zaytsev_ra2\PycharmProjects\Контроль бюджета\Ставки")
RATES_PATTERN = "employee_rate_directory_*.xlsx"

# ========= ВРЕМЕННЫЙ «ЖЁСТКИЙ» ИСТОЧНИК НОРМ (производственный календарь РФ, 2025) =========
EXPECTED_WORKDAYS_2025: Dict[str, int] = {
    "2025-01": 17,
    "2025-02": 20,
    "2025-03": 21,
    "2025-04": 22,
    "2025-05": 18,
    "2025-06": 19,
    "2025-07": 23,
    "2025-08": 21,
    "2025-09": 22,
    "2025-10": 23,
    "2025-11": 19,
    "2025-12": 22,
}

def workdays_for_ym(ym: str) -> int:
    """
    ВРЕМЕННО: возвращает число рабочих дней ТОЛЬКО для 2025 из зашитого словаря.
    Если месяц вне 2025 — скрипт падает, чтобы не было «тихих» расхождений.
    """
    if not ym:
        raise SystemExit("[ERROR] workdays_for_ym: пустой ym")
    if ym in EXPECTED_WORKDAYS_2025:
        return EXPECTED_WORKDAYS_2025[ym]
    raise SystemExit(f"[ERROR] Нет нормы для {ym}. Сейчас разрешён только 2025 год (см. EXPECTED_WORKDAYS_2025).")

# ========= Helpers: выбор колонок/файлов и пр. =========
def _pick_latest_file(folder: Path, pattern: str) -> Optional[Path]:
    files = sorted(Path(folder).glob(pattern), key=lambda p: p.stat().st_mtime, reverse=True)
    return files[0] if files else None

def _pick_col(df: pd.DataFrame, candidates):
    low = {c.lower(): c for c in df.columns}
    for cand in candidates:
        cl = cand.strip().lower()
        if cl in low:
            return low[cl]
    for cand in candidates:
        cl = cand.strip().lower()
        for c in df.columns:
            if cl in c.strip().lower():
                return c
    return None

def normalize_employee_name(name: str) -> str:
    if name is None:
        return ""
    s = str(name)
    s = s.replace("\u00a0", " ").replace("\u202f", " ")
    s = re.sub(r'\s*(\[[^\]]+\]\s*)+$', '', s).strip()
    s = re.sub(r'\s+', ' ', s)
    return s

def load_rate_directory_or_none(folder: Path, pattern: str) -> Optional[pd.DataFrame]:
    path = _pick_latest_file(folder, pattern)
    if path is None:
        print(f"[RATES] Нет файлов в '{folder}' по маске '{pattern}' — пропускаю ставки.")
        return None
    try:
        rdf = pd.read_excel(path)
    except Exception as e:
        print(f"[RATES] Ошибка чтения '{path}': {e} — пропускаю ставки.")
        return None
    emp  = _pick_col(rdf, ["Сотрудник","ФИО","Сотрудник ФИО"])
    rate = _pick_col(rdf, ["Ставка","Ставка, ₽/ч","Ставка (₽/ч)","Стоимость часа","Цена часа"])
    cc   = _pick_col(rdf, ["Сотрудник:ЦК","ЦК","Cost Center","СЦК"])
    dept = _pick_col(rdf, ["Сотрудник:Направление","Направление","Отдел","Департамент"])
    cat  = _pick_col(rdf, ["Сотрудник:Категория","Категория сотрудника","Категория"])
    if not emp or not rate:
        print(f"[RATES] В '{path.name}' нет обязательных колонок (Сотрудник/Ставка) — пропускаю ставки.")
        return None
    rename = {emp:"Сотрудник", rate:"Ставка"}
    if cc:   rename[cc]   = "Сотрудник:ЦК"
    if dept: rename[dept] = "Сотрудник:Направление"
    if cat:  rename[cat]  = "Сотрудник:Категория"
    rdf = rdf.rename(columns=rename)
    rdf["Ставка"] = pd.to_numeric(rdf["Ставка"], errors="coerce")
    rdf["Сотрудник_norm"] = rdf["Сотрудник"].apply(normalize_employee_name)
    keep = [c for c in ["Сотрудник","Ставка","Сотрудник:ЦК","Сотрудник:Направление","Сотрудник:Категория","Сотрудник_norm"] if c in rdf.columns]
    rdf = rdf[keep].dropna(subset=["Сотрудник_norm"]).drop_duplicates(subset=["Сотрудник_norm"])
    print(f"[RATES] Загружен справочник '{path.name}': {len(rdf)} сотрудников")
    return rdf

def enrich_with_rates(df: pd.DataFrame, rates: Optional[pd.DataFrame]) -> pd.DataFrame:
    if rates is None or rates.empty:
        return df
    if "Сотрудник" not in df.columns:
        emp = _pick_col(df, ["Сотрудник","ФИО","Сотрудник ФИО"])
        if not emp:
            print("[RATES] Нет колонки 'Сотрудник' — пропускаю ставки.")
            return df
        if emp != "Сотрудник":
            df = df.rename(columns={emp:"Сотрудник"})
    df["Сотрудник_norm"] = df["Сотрудник"].apply(normalize_employee_name)
    if "Сотрудник_norm" not in rates.columns:
        rates["Сотрудник_norm"] = rates["Сотрудник"].apply(normalize_employee_name)
    merged = df.merge(rates, on="Сотрудник_norm", how="left", suffixes=("", "_rate"))
    if "Ставка, ₽/ч" in merged.columns and "Ставка" not in merged.columns:
        merged = merged.rename(columns={"Ставка, ₽/ч": "Ставка"})
    hours_col = _pick_col(merged, ["Часы факт","Часы","Hours","Время, ч"])
    if hours_col:
        rate_col = "Ставка" if "Ставка" in merged.columns else ("Ставка, ₽/ч" if "Ставка, ₽/ч" in merged.columns else None)
        if rate_col:
            merged["Стоимость, ₽"] = (merged[hours_col].fillna(0) * merged[rate_col].fillna(0)).round(2)
    if "Ставка, ₽/ч" in merged.columns and "Ставка" in merged.columns:
        merged = merged.drop(columns=["Ставка, ₽/ч"])
    for c in ["Сотрудник_rate","Сотрудник_norm"]:
        if c in merged.columns:
            merged = merged.drop(columns=[c])
    return merged

FINAL_ORDER = ["Тип задачи", "Ссылка на задачу", "Описание", "Метки", "Проект", "Сервис", "Месяц",
               "Сотрудник", "Сотрудник:Категория", "Сотрудник:ЦК", "Сотрудник:Направление",
               "Тип активности", "Часы факт", "FTE факт", "Ставка", "Стоимость, ₽"]

def reorder_final(df: pd.DataFrame) -> pd.DataFrame:
    keep = [c for c in FINAL_ORDER if c in df.columns]
    rest = [c for c in df.columns if c not in keep]
    return df[keep + rest]

COLUMNS_MAP_PATH = Path(__file__).with_name("columns_map.json")

HEADERS = {
    "Authorization": f"Bearer {BEARER_TOKEN}",
    "Content-Type": "application/json",
    "Accept": "application/json"
}

# ========= Умный автофит =========
WIDTH_OVERRIDES = {"Ссылка на задачу": 16, "Сервис": 34, "Описание": 60}
CLAMP_MIN, CLAMP_MAX = 6, 60

def _visible_text(cell_val):
    if not isinstance(cell_val, str):
        return "" if cell_val is None else str(cell_val)
    s = cell_val.strip()
    if not s.startswith("="):
        return s
    m = re.match(r'^\s*=\s*HYPERLINK\s*\(\s*"[^"]*"\s*[,;]\s*"([^"]*)"\s*\)\s*$', s, re.IGNORECASE)
    return m.group(1) if m else s

def excel_autofit_smart(path: Path):
    try:
        from openpyxl import load_workbook
        wb = load_workbook(path)
        for ws in wb.worksheets:
            headers = {cell.column: (cell.value or "") for cell in ws[1]}
            for col in ws.columns:
                col_idx = col[0].column
                head = str(headers.get(col_idx, "")).strip()
                if head in WIDTH_OVERRIDES:
                    ws.column_dimensions[col[0].column_letter].width = WIDTH_OVERRIDES[head]
                    continue
                max_len = max(len(_visible_text(c.value)) for c in col)
                max_len = max(max_len, len(head))
                ws.column_dimensions[col[0].column_letter].width = max(CLAMP_MIN, min(max_len + 2, CLAMP_MAX))
        wb.save(path)
    except Exception as e:
        print(f"[autofit] пропущено: {e}")

# ========= JSON helpers =========
def load_json(path: Path) -> Dict[str, str]:
    if path.exists():
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception:
            return {}
    return {}

def save_json(path: Path, data: Dict[str, str]):
    try:
        with open(path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False)
    except Exception as e:
        print(f"[cache] не удалось сохранить {path.name}: {e}")

# ========= Jira/Tempo helpers =========
def get_display_name(wid: str) -> Tuple[str, str]:
    url = "{}/rest/api/2/user?key={}".format(JIRA_URL, wid)
    try:
        r = requests.get(url, headers=HEADERS, timeout=10)
        if r.status_code == 200:
            user = r.json()
            return wid, user.get("displayName", wid)
    except Exception:
        time.sleep(0.2)
    return wid, wid

def fetch_issue_summary_labels(issue_key: str) -> Tuple[str, Dict[str, str]]:
    url = "{}/rest/api/2/issue/{}?fields=summary,labels".format(JIRA_URL, issue_key)
    try:
        r = requests.get(url, headers=HEADERS, timeout=10)
        if r.status_code == 200:
            data = r.json() or {}
            fields = data.get("fields") or {}
            return issue_key, {
                "summary": fields.get("summary", "") or "",
                "labels": ",".join(fields.get("labels") or [])
            }
    except Exception:
        time.sleep(0.2)
    return issue_key, {"summary": "", "labels": ""}

def sanitize_for_account(title: str) -> str:
    if title is None:
        return ""
    s = " ".join(str(title).replace("\n", " ").replace("\r", " ").split())
    return s[:100]

def hyperlink_formula(jira_base_url: str, key: str) -> str:
    """Excel HYPERLINK без f-строк (совместимо)."""
    if not key:
        return ""
    k = str(key).strip().replace('"', '""')
    base = str(jira_base_url).rstrip('/')
    return '=HYPERLINK("{}", "{}")'.format("{}/browse/{}".format(base, k), k)

# ========= Tempo fetch =========
tempo_url = "{}/rest/tempo-timesheets/4/worklogs/search".format(JIRA_URL)
payload = {"from": FROM_DATE, "to": TO_DATE}
resp = requests.post(tempo_url, json=payload, headers=HEADERS, timeout=120)
if resp.status_code != 200:
    print("Ошибка запроса к Tempo:", resp.status_code, resp.text); raise SystemExit(1)
worklogs = resp.json() or []

# ========= Users cache =========
worker_ids = list({w.get("worker") for w in worklogs if w.get("worker")})
worker_map_path = WL_DIR / 'worker_map.json'
worker_map = load_json(worker_map_path)
new_ids = [wid for wid in worker_ids if wid and wid not in worker_map]
if new_ids:
    print("Новых пользователей: {} — обновляем кэш...".format(len(new_ids)))
    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as ex:
        for wid, name in ex.map(get_display_name, new_ids):
            worker_map[wid] = name
    save_json(worker_map_path, worker_map)

# ========= Summary/labels cache =========
summary_labels_cache_path = WL_DIR / "issue_summary_labels_cache.json"
summary_labels_cache = load_json(summary_labels_cache_path)

all_issue_keys = sorted({(w.get("issue") or {}).get("key") for w in worklogs if (w.get("issue") or {}).get("key")})
need_keys_sl = [k for k in all_issue_keys if k and k not in summary_labels_cache]
if need_keys_sl:
    print("Новых issues для summary+labels: {}".format(len(need_keys_sl)))
    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as ex:
        for ikey, data in ex.map(fetch_issue_summary_labels, need_keys_sl):
            summary_labels_cache[ikey] = data
    save_json(summary_labels_cache_path, summary_labels_cache)

# ========= Rows build =========
def parse_started_ts(value) -> Optional[datetime]:
    """Tempo started (UTC aware) → локальное наивное время (TIMEZONE)."""
    try:
        ts = pd.to_datetime(value, utc=True, errors="coerce")
        if pd.isna(ts):
            return None
        ts = ts.tz_convert(TIMEZONE).tz_localize(None)
        return ts.to_pydatetime()
    except Exception:
        return None

rows = []
filled_cnt = 0

for w in worklogs:
    issue = w.get("issue") or {}
    attrs = w.get("attributes") or {}
    activity_type = (attrs.get("_Типактивности_", {}) or {}).get("value")

    started_dt = parse_started_ts(w.get("started"))
    ym = started_dt.strftime("%Y-%m") if started_dt else None
    mmYYYY = started_dt.strftime("%m/%Y") if started_dt else None

    hours = (w.get("timeSpentSeconds") or 0) / 3600.0

    # FTE построчно строго от рабочих дней ФАКТИЧЕСКОГО месяца (зашитые нормы 2025):
    days_norm = workdays_for_ym(ym) if ym else None
    if days_norm is None:
        fte = None
    else:
        fte = (hours / (8.0 * days_norm)) if days_norm else None

    issue_key   = (issue.get("key") or "").strip()
    project_key = issue.get("projectKey")
    issue_type  = issue.get("issueType")
    account_key = issue.get("accountKey")

    sl = summary_labels_cache.get(issue_key) or {"summary": "", "labels": ""}
    summary_for_report = sl.get("summary", "") or ""
    labels_for_report  = sl.get("labels", "") or ""

    if FILL_ACCOUNT_ENABLED and project_key in FILL_ACCOUNT_PROJECTS and not str(account_key or "").strip():
        smry = summary_for_report or issue_key
        account_key = "{}{}".format(FILL_ACCOUNT_PREFIX, sanitize_for_account(smry)) if FILL_ACCOUNT_PREFIX else sanitize_for_account(smry)
        filled_cnt += 1

    rows.append({
        "IssueKey_tmp": issue_key,
        "Worker Name":  worker_map.get(w.get("worker"), w.get("worker")),
        "Account Key":  account_key,
        "Project Key":  project_key,
        "Issue Type":   issue_type,
        "Activity Type":activity_type,
        "Started (mm/yyyy)": mmYYYY,
        "Time Spent (h)": round(hours, 2),
        "FTE":                round(fte, 3) if fte is not None else None,
        "Summary":            summary_for_report,
        "Labels":             labels_for_report,
        "_ym":                ym,  # для агрегации
    })

print("Автозаполнение Account Key из summary: {} задач.".format(filled_cnt))

df = pd.DataFrame(rows)

# ========= RU + ссылка =========
def hyperlink_formula_safe(jira_base_url: str, key: str) -> str:
    if not key:
        return ""
    k = str(key).strip().replace('"', '""')
    base = str(jira_base_url).rstrip('/')
    return '=HYPERLINK("{}", "{}")'.format("{}/browse/{}".format(base, k), k)

df.insert(0, "Ссылка на задачу", df["IssueKey_tmp"].map(lambda k: hyperlink_formula_safe(JIRA_URL, k)))
df.drop(columns=["IssueKey_tmp"], inplace=True)
df.rename(columns={
    "Worker Name":        "Сотрудник",
    "Account Key":        "Сервис",
    "Project Key":        "Проект",
    "Issue Type":         "Тип задачи",
    "Activity Type":      "Тип активности",
    "Started (mm/yyyy)":  "Месяц",
    "Time Spent (h)":     "Часы факт",
    "FTE":                "FTE факт",
    "Summary":            "Описание",
    "Labels":             "Метки",
}, inplace=True)

RU_ORDER = ["Тип задачи","Ссылка на задачу","Описание","Метки","Проект","Сервис","Месяц",
            "Сотрудник","Сотрудник:Категория","Сотрудник:ЦК","Сотрудник:Направление",
            "Тип активности","Часы факт","FTE факт","Ставка","Стоимость, ₽"]
df = df[[c for c in RU_ORDER if c in df.columns] + [c for c in df.columns if c not in RU_ORDER]]

# ====== Ставки ======
try:
    _rates_df = load_rate_directory_or_none(RATES_FOLDER, RATES_PATTERN)
    df = enrich_with_rates(df, _rates_df)
    df = reorder_final(df)
except Exception as _e:
    print("[RATES] Ошибка обогащения ставками: {}".format(_e))

# ========= Агрегация (векторно) =========
# тех. ключ месяца
if "_ym" not in df.columns:
    df["_ym"] = pd.to_datetime(df["Месяц"], format="%m/%Y", errors="coerce").dt.strftime("%Y-%m")

# 1) по сотруднику и месяцу
monthly = (
    df.groupby(["_ym", "Сотрудник"], dropna=False)["Часы факт"]
      .sum()
      .reset_index()
      .rename(columns={"_ym": "Месяц (YYYY-MM)"})
)
monthly["Норма_дней"]  = monthly["Месяц (YYYY-MM)"].map(workdays_for_ym).astype("Int64")
monthly["Норма_часов"] = (8 * monthly["Норма_дней"]).astype("Int64")
monthly["FTE месяц"]   = (monthly["Часы факт"] / monthly["Норма_часов"]).round(3)

# 2) итого по месяцу
monthly_total = (
    monthly.groupby(["Месяц (YYYY-MM)"])["Часы факт"]
           .sum()
           .reset_index()
)
monthly_total["Норма_дней"]  = monthly_total["Месяц (YYYY-MM)"].map(workdays_for_ym).astype("Int64")
monthly_total["Норма_часов"] = (8 * monthly_total["Норма_дней"]).astype("Int64")
monthly_total["FTE месяц (итого)"] = (monthly_total["Часы факт"] / monthly_total["Норма_часов"]).round(3)

# ========= Excel =========
stamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
raw_path = WL_DIR / "worklogs_{}.xlsx".format(stamp)
with pd.ExcelWriter(raw_path, engine="openpyxl") as w:
    df.to_excel(w, index=False, sheet_name="worklogs_raw")
    monthly.to_excel(w, index=False, sheet_name="monthly_fte")
    monthly_total.to_excel(w, index=False, sheet_name="monthly_total")
if EXCEL_AUTOFIT:
    excel_autofit_smart(raw_path)
print("✅ RAW: {}".format(raw_path))

# ========= Canonical =========
columns_map = load_columns_map(COLUMNS_MAP_PATH)
df_can, canon_log = canonize_fact(df, columns_map, coerce_types=True)
if "Месяц" in df_can.columns:     df_can["Месяц"] = df_can["Месяц"].map(to_mmYYYY)
if "Сотрудник" in df_can.columns: df_can["Сотрудник"] = df_can["Сотрудник"].map(norm_text)
if "Сервис" in df_can.columns:    df_can["Сервис"] = df_can["Сервис"].map(norm_text)
if "Сотрудник:Логин" in df_can.columns:
    df_can.drop(columns=["Сотрудник:Логин"], inplace=True, errors="ignore")
df_can = df_can[[c for c in RU_ORDER if c in df_can.columns] + [c for c in df_can.columns if c not in RU_ORDER]]

can_path = WL_OUT_DIR / "worklogs_canonical_{}.xlsx".format(stamp)
with pd.ExcelWriter(can_path, engine="openpyxl") as w:
    df_can.to_excel(w, index=False, sheet_name="worklogs")
    monthly.to_excel(w, index=False, sheet_name="monthly_fte")
    monthly_total.to_excel(w, index=False, sheet_name="monthly_total")
    if not canon_log.empty:
        canon_log.to_excel(w, index=False, sheet_name="canonical_log")
if EXCEL_AUTOFIT:
    excel_autofit_smart(can_path)

write_schema_json(can_path.with_suffix(".schema.json"),
                  {"worklogs": df_can, "monthly_fte": monthly, "monthly_total": monthly_total})
print("✅ Canonical: {}".format(can_path))
print("🧾 Schema:    {}".format(can_path.with_suffix(".schema.json")))

# ========= Диагностика (пример: май 2025) =========
try:
    ym_check = "2025-05"
    may_hours_total = float(monthly_total.loc[monthly_total["Месяц (YYYY-MM)"].eq(ym_check), "Часы факт"].sum())
    rdays = workdays_for_ym(ym_check)
    denom = 8 * rdays
    if denom:
        print("[CHECK] МАЙ 2025: Σчасы={}, раб_дней={}, знаменатель={}, FTE={:.3f}".format(
            may_hours_total, rdays, denom, (may_hours_total/denom if denom else 0)))
except Exception as e:
    print("[CHECK] Ошибка диагностики мая: {}".format(e))
