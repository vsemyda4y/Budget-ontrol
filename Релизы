# -*- coding: utf-8 -*-
"""
Release Composer — выгрузка состава релизов по коду проекта JIRA
(эпики → истории/задачи → сабтаски) + связи задач (в т.ч. виртуальная иерархия по типам) → Excel c иерархией.

Выходной Excel:
- <Release>_Tree — иерархия с «ёлочкой», цветами блоков и уровнями.
- Overview — 1) количество задач по типам; 2) % покрытия артефактами (кластеризация: L1 + его L2 = 1 задача).

Итоговые колонки ..._Tree:
Level, Блок, Краткое содержание, Задача, Тип, Статус, Услуга, Артефакт, Release Note, Исполнитель, Fix Versions
"""

import os
import re
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import pandas as pd
import requests
from openpyxl import load_workbook
from openpyxl.styles import Alignment, PatternFill, Font
from openpyxl.utils import get_column_letter
from openpyxl.worksheet.worksheet import Worksheet

# ========= ENV =========

def _env(key: str, default: Optional[str] = None) -> str:
    val = os.getenv(key)
    if val is None:
        return default or ""
    val = str(val).strip()
    if val.lower() in {"none", "null", "", "-", "—", "–"}:
        return default or ""
    return val

JIRA_URL               = _env("JIRA_URL", "https://jira.nlmk.com").rstrip("/")
JIRA_BEARER_TOKEN      = _env("JIRA_BEARER_TOKEN", _env("JIRA_TEMPO_TOKEN", ""))
PROJECT_KEY            = _env("PROJECT_KEY", "CSHRM")
VERSIONS_FILTER        = [v.strip() for v in _env("VERSIONS_FILTER", "").split(",") if v.strip()]
ONLY_UNRELEASED        = _env("ONLY_UNRELEASED", "1") == "1"
MAX_ISSUES             = int(_env("MAX_ISSUES", "5000"))
ENABLE_LINK_HIERARCHY  = _env("ENABLE_LINK_HIERARCHY", "1") == "1"
CONFLUENCE_HOST        = _env("CONFLUENCE_HOST", "confluence")
RELEASE_NOTE_FIELD_ID  = _env("RELEASE_NOTE_FIELD_ID", "")
SERVICE_FIELD_ID       = _env("SERVICE_FIELD_ID", "")
COLLAPSE_LEVEL         = int(_env("COLLAPSE_LEVEL", "1"))

if not PROJECT_KEY:
    raise SystemExit("PROJECT_KEY не задан.")
if not JIRA_BEARER_TOKEN:
    raise SystemExit("JIRA_BEARER_TOKEN не задан.")

HEADERS = {"Authorization": f"Bearer {JIRA_BEARER_TOKEN}",
           "Accept": "application/json",
           "Content-Type": "application/json"}

OUT_DIR = Path.cwd() / "release_export"
OUT_DIR.mkdir(parents=True, exist_ok=True)

# ========= Excel utils =========

def make_sheet_name(base: str, suffix: str) -> str:
    safe = re.sub(r'[:\\/?*\[\]]', '_', str(base or 'Release'))
    max_base = 31 - (len(suffix) + 1)
    if max_base < 1: max_base = 1
    safe = safe[:max_base]
    return f"{safe}_{suffix}"

def _visible_text(val: object) -> str:
    if val is None: return ""
    s = str(val)
    if not s.startswith("="): return s
    m = re.match(r'^\s*=\s*HYPERLINK\s*\(\s*"[^"]*"\s*[,;]\s*"([^"]*)"\s*\)\s*$', s, re.IGNORECASE)
    return m.group(1) if m else s

def excel_autofit_smart(path: Path, width_overrides: Optional[Dict[str,int]] = None,
                        clamp_min: int = 6, clamp_max: int = 60):
    try:
        wb = load_workbook(path)
        for ws in wb.worksheets:
            header_row_idx = 1
            for r in range(1, min(6, ws.max_row + 1)):
                vals = [str(c.value).strip() if c.value else "" for c in ws[r]]
                if "Level" in vals or "Release" in vals:
                    header_row_idx = r
                    break
            headers = {cell.column: (cell.value or "") for cell in ws[header_row_idx]}
            for col_cells in ws.iter_cols(min_col=1, max_col=ws.max_column,
                                          min_row=header_row_idx, max_row=ws.max_row):
                col_idx = col_cells[0].column
                head = str(headers.get(col_idx, "")).strip()
                if width_overrides and head in width_overrides:
                    ws.column_dimensions[get_column_letter(col_idx)].width = width_overrides[head]
                    continue
                max_len = max(len(_visible_text(c.value)) if c.value is not None else 0 for c in col_cells)
                max_len = max(max_len, len(head))
                ws.column_dimensions[get_column_letter(col_idx)].width = max(clamp_min, min(max_len + 2, clamp_max))
        wb.save(path)
    except Exception as e:
        print(f"[autofit] пропущено: {e}")

def hyperlink_formula(key: str) -> str:
    if not key: return ""
    k = str(key).strip().replace('"', '""')
    return f'=HYPERLINK("{JIRA_URL}/browse/{k}","{k}")'

def apply_wrap(ws: Worksheet, headers_to_wrap: List[str], header_row_idx: int):
    header_to_col: Dict[str, int] = {}
    for cell in ws[header_row_idx]:
        if cell.value: header_to_col[str(cell.value).strip()] = cell.column
    for h in headers_to_wrap:
        col = header_to_col.get(h)
        if not col: continue
        for row in ws.iter_rows(min_row=header_row_idx, max_row=ws.max_row, min_col=col, max_col=col):
            cell = row[0]
            cell.alignment = Alignment(wrap_text=True, vertical="top")

def align_top_all(ws: Worksheet, header_row_idx: int):
    for row in ws.iter_rows(min_row=header_row_idx, max_row=ws.max_row, min_col=1, max_col=ws.max_column):
        for cell in row:
            cell.alignment = Alignment(
                wrap_text=cell.alignment.wrap_text,
                horizontal=cell.alignment.horizontal,
                vertical="top"
            )

def apply_row_styles(ws: Worksheet, header_row_idx: int):
    headers = {str(c.value).strip(): c.column for c in ws[header_row_idx] if c.value}
    col_level = headers.get("Level"); col_block = headers.get("Блок")
    if not col_level: return
    fill_dev  = PatternFill(fill_type="solid", fgColor="E6F2FF")  # Развитие
    fill_sup  = PatternFill(fill_type="solid", fgColor="FFF2CC")  # Сопровождение
    fill_lvl1 = PatternFill(fill_type="solid", fgColor="E8F5E9")  # Level 1 — light green
    fill_lvl2 = PatternFill(fill_type="solid", fgColor="FFE0B2")  # Level 2 — light orange

    for i in range(header_row_idx + 1, ws.max_row + 1):
        try: level = int(ws.cell(row=i, column=col_level).value or 0)
        except Exception: level = 0
        if level == 0:
            for j in range(1, ws.max_column + 1):
                ws.cell(row=i, column=j).font = Font(bold=True)
        row_fill = None
        if col_block:
            block = str(ws.cell(row=i, column=col_block).value or "").strip().lower()
            row_fill = fill_dev if block == "развитие" else fill_sup if block == "сопровождение" else None
        if level == 1: row_fill = fill_lvl1
        elif level == 2: row_fill = fill_lvl2
        if row_fill:
            for j in range(1, ws.max_column + 1):
                ws.cell(row=i, column=j).fill = row_fill

def insert_legend(ws: Worksheet, text: str):
    ws.insert_rows(1)
    last_col_letter = get_column_letter(ws.max_column)
    ws.merge_cells(f"A1:{last_col_letter}1")
    c = ws["A1"]
    c.value = text
    c.alignment = Alignment(horizontal="left", vertical="center", wrap_text=True)
    c.font = Font(bold=True)
    c.fill = PatternFill(fill_type="solid", fgColor="DDDDDD")

# ========= Jira helpers =========

SESSION = requests.Session()
SESSION.headers.update(HEADERS)

def jira_get(url: str, params: Optional[dict] = None) -> dict:
    r = SESSION.get(url, params=params, timeout=60)
    if r.status_code != 200:
        raise RuntimeError(f"GET {url} → {r.status_code}: {r.text[:500]}")
    return r.json()

def jira_post(url: str, payload: dict) -> dict:
    r = SESSION.post(url, json=payload, timeout=120)
    if r.status_code != 200:
        raise RuntimeError(f"POST {url} → {r.status_code}: {r.text[:500]}")
    return r.json()

def get_field_ids() -> Dict[str, str]:
    fields = jira_get(f"{JIRA_URL}/rest/api/2/field")
    epic_link_id = None
    story_points_id = None
    release_note_id = RELEASE_NOTE_FIELD_ID or None
    service_id = SERVICE_FIELD_ID or None
    rn_synonyms = {"release note", "release notes", "релизные заметки", "релиз нота", "релиз-нота"}
    service_synonyms = {"service", "услуга"}
    for f in fields:
        name = (f.get("name") or "").strip().lower()
        fid = f.get("id")
        if name == "epic link": epic_link_id = fid
        if name == "story points": story_points_id = fid
        if not release_note_id and name in rn_synonyms: release_note_id = fid
        if not service_id and name in service_synonyms: service_id = fid
    return {"epic_link": epic_link_id, "story_points": story_points_id,
            "release_note": release_note_id, "service": service_id}

# ========= Link hierarchy rules =========

LINK_HIERARCHY_RULES = [
    ("engineering concept", "change request"),
    ("support", "bugfix"),
]

def _block_by_type(issue_type: str) -> str:
    t = (issue_type or "").strip().lower()
    if t in {"engineering concept", "change request"}: return "Развитие"
    if t in {"support", "bugfix"}: return "Сопровождение"
    return ""

# ========= Tree build =========

EPIC_LINK_FIELD_ID: Optional[str] = None
STORY_POINTS_FIELD_ID: Optional[str] = None
RELEASE_NOTE_FIELD_ID_RESOLVED: Optional[str] = None
SERVICE_FIELD_ID_RESOLVED: Optional[str] = None

def flatten_release_tree(release_name: str, issues: List[dict], epic_link_field: Optional[str]) -> Tuple[pd.DataFrame, pd.DataFrame]:
    by_key = {i.get("key"): i for i in issues}

    def _g(obj, path: List[str]):
        for p in path:
            if obj is None: return None
            obj = obj.get(p) if isinstance(obj, dict) else None
        return obj

    children: Dict[str, List[str]] = {}
    epic_children: Dict[str, List[str]] = {}
    parent_map: Dict[str, Optional[str]] = {}
    epic_of: Dict[str, Optional[str]] = {}
    links_rows: List[dict] = []
    link_pairs: List[Tuple[str, str]] = []

    def issue_type_name(i: dict) -> str:
        return _g(i.get("fields", {}), ["issuetype", "name"]) or ""

    for k, it in by_key.items():
        f = it.get("fields", {})
        parent = _g(f, ["parent", "key"]) or None
        parent_map[k] = parent
        if parent: children.setdefault(parent, []).append(k)
        epic = f.get(epic_link_field) if epic_link_field else None
        if isinstance(epic, dict): epic = epic.get("key")
        epic_of[k] = epic
        if epic: epic_children.setdefault(epic, []).append(k)
        for l in f.get("issuelinks") or []:
            ltype = _g(l, ["type", "name"]) or ""
            inward = _g(l, ["inwardIssue", "key"]) or None
            outward = _g(l, ["outwardIssue", "key"]) or None
            if inward:
                links_rows.append({"From": k, "Direction": "inward", "Type": ltype, "To": inward})
                link_pairs.append((k, inward))
            if outward:
                links_rows.append({"From": k, "Direction": "outward", "Type": ltype, "To": outward})
                link_pairs.append((k, outward))

    # virtual parent-child by link types
    if ENABLE_LINK_HIERARCHY and LINK_HIERARCHY_RULES:
        rules = [(a.lower(), b.lower()) for a, b in LINK_HIERARCHY_RULES]
        for a, b in link_pairs:
            ia = by_key.get(a); ib = by_key.get(b)
            if not ia or not ib: continue
            ta = issue_type_name(ia).lower(); tb = issue_type_name(ib).lower()
            if (ta, tb) in rules and not parent_map.get(b) and not epic_of.get(b):
                parent_map[b] = a; children.setdefault(a, []).append(b)
            if (tb, ta) in rules and not parent_map.get(a) and not epic_of.get(a):
                parent_map[a] = b; children.setdefault(b, []).append(a)

    def _tree_prefix(prefix_last_flags: List[bool], is_last: Optional[bool]) -> str:
        if not prefix_last_flags and is_last is None: return ""
        parts: List[str] = []
        for last in prefix_last_flags: parts.append("   " if last else "│  ")
        if is_last is not None: parts.append("└─ " if is_last else "├─ ")
        return "".join(parts)

    epics = [k for k, it in by_key.items() if issue_type_name(it).lower() == "epic"]
    roots_wo_epic = [k for k, it in by_key.items() if (k not in epics and not parent_map.get(k) and not epic_of.get(k))]

    _artifact_cache: Dict[str, str] = {}
    def artifact_for(key: str) -> str:
        if key not in _artifact_cache:
            # remotelink → confluence
            try:
                arr = jira_get(f"{JIRA_URL}/rest/api/2/issue/{key}/remotelink")
            except Exception:
                arr = []
            host = CONFLUENCE_HOST.lower().strip()
            link = ""
            for rl in arr or []:
                obj = (rl or {}).get("object") or {}
                url = (obj.get("url") or "").strip()
                title = (obj.get("title") or "Confluence").strip()
                if url and (host in url.lower()):
                    u = url.replace('"', '""'); t = title.replace('"', '""')
                    link = f'=HYPERLINK("{u}","{t}")'
                    break
            _artifact_cache[key] = link
        return _artifact_cache[key]

    def _extract_field_value(raw):
        if isinstance(raw, dict): return str(raw.get("value") or raw.get("name") or raw.get("displayName") or "")
        if isinstance(raw, list): return ", ".join(str(x.get("value") if isinstance(x, dict) else x) for x in raw if x not in (None, ""))
        return "" if raw is None else str(raw)

    rows: List[dict] = []

    def row_from_key(key: str, level: int, rel_name: str, prefix: str) -> dict:
        it = by_key[key]; f = it.get("fields", {})
        assignee = _g(f, ["assignee", "displayName"]) or ""
        status = _g(f, ["status", "name"]) or ""
        issue_type = _g(f, ["issuetype", "name"]) or ""
        summary = f.get("summary") or ""
        release_note = _extract_field_value(f.get(RELEASE_NOTE_FIELD_ID_RESOLVED)) if RELEASE_NOTE_FIELD_ID_RESOLVED else ""
        service_val  = _extract_field_value(f.get(SERVICE_FIELD_ID_RESOLVED)) if SERVICE_FIELD_ID_RESOLVED else ""
        fix_versions = ", ".join((v.get("name") for v in (f.get("fixVersions") or [])))
        block = _block_by_type(issue_type)
        return {
            # служебные ключи для расчётов Overview (не выводим в Excel)
            "_Key": key,
            "_ParentKey": parent_map.get(key),
            "Release": rel_name,
            "Level": level,
            "Блок": block,
            "Краткое содержание": prefix + summary,
            "Задача": hyperlink_formula(key),
            "Тип": issue_type,
            "Статус": status,
            "Услуга": service_val,
            "Артефакт": artifact_for(key),
            "Release Note": release_note,
            "Исполнитель": assignee,
            "Fix Versions": fix_versions,
        }

    def _sorted_kids(parent_key: str) -> List[str]:
        return sorted(children.get(parent_key, []))

    def walk_issue(key: str, level: int, prefix_flags: List[bool], is_last: Optional[bool]):
        prefix = _tree_prefix(prefix_flags, is_last)
        rows.append(row_from_key(key, level, release_name, prefix))
        kids = _sorted_kids(key)
        for idx, ch in enumerate(kids):
            last = (idx == len(kids) - 1)
            walk_issue(ch, level + 1, prefix_flags + [is_last if is_last is not None else True], last)

    for e in sorted(epics):
        rows.append(row_from_key(e, 0, release_name, prefix=""))
        first_level = sorted(set(children.get(e, []) + epic_children.get(e, [])))
        for idx, k in enumerate(first_level):
            last = (idx == len(first_level) - 1)
            walk_issue(k, 1, [], last)

    if roots_wo_epic:
        rows.append({
            "_Key": "",
            "_ParentKey": "",
            "Release": release_name,
            "Level": 0,
            "Блок": "",
            "Краткое содержание": "(без эпика)",
            "Задача": "",
            "Тип": "",
            "Статус": "",
            "Услуга": "",
            "Артефакт": "",
            "Release Note": "",
            "Исполнитель": "",
            "Fix Versions": "",
        })
        for idx, k in enumerate(sorted(roots_wo_epic)):
            last = (idx == len(roots_wo_epic) - 1)
            walk_issue(k, 1, [], last)

    tree_df = pd.DataFrame(rows)
    links_df = pd.DataFrame(links_rows) if links_rows else pd.DataFrame(columns=["From","Direction","Type","To"])
    return tree_df, links_df

# ========= Main =========

def main():
    global EPIC_LINK_FIELD_ID, STORY_POINTS_FIELD_ID, RELEASE_NOTE_FIELD_ID_RESOLVED, SERVICE_FIELD_ID_RESOLVED

    print("=== Release Composer: старт ===")
    versions = list_versions(PROJECT_KEY)
    if not versions:
        raise SystemExit("Нет подходящих версий")

    ids = get_field_ids()
    EPIC_LINK_FIELD_ID = ids.get("epic_link")
    STORY_POINTS_FIELD_ID = ids.get("story_points")
    RELEASE_NOTE_FIELD_ID_RESOLVED = ids.get("release_note") or (RELEASE_NOTE_FIELD_ID or None)
    SERVICE_FIELD_ID_RESOLVED = ids.get("service") or (SERVICE_FIELD_ID or None)

    fields = ["summary", "issuetype", "status", "assignee", "parent",
              "subtasks", "issuelinks", "priority", "fixVersions"]
    if EPIC_LINK_FIELD_ID: fields.append(EPIC_LINK_FIELD_ID)
    if RELEASE_NOTE_FIELD_ID_RESOLVED: fields.append(RELEASE_NOTE_FIELD_ID_RESOLVED)
    if SERVICE_FIELD_ID_RESOLVED: fields.append(SERVICE_FIELD_ID_RESOLVED)

    per_release = []            # (vname, tree_df_final, links_df, ov_df_types, coverage_row)
    overview_rows_types: List[pd.DataFrame] = []
    coverage_rows: List[dict] = []

    for v in versions:
        vname = v.get("name")
        print(f"→ Версия: {vname}")
        jql = f'project={PROJECT_KEY} AND fixVersion="{vname}" ORDER BY issuetype, key'
        issues = jql_search(jql, fields, max_results=MAX_ISSUES)
        if not issues:
            print("  (нет задач)")
            continue

        # Build tree (служебные _Key/_ParentKey остаются внутри до финального отбора колонок)
        tree_full, links_df = flatten_release_tree(vname, issues, EPIC_LINK_FIELD_ID)

        # --- Coverage calc: L1 + его L2 = 1 кластер ---
        df12 = tree_full[tree_full["Level"].isin([1, 2])].copy()
        if not df12.empty:
            def cluster_id(row):
                try:
                    lvl = int(row["Level"])
                except Exception:
                    lvl = 0
                if lvl == 1:
                    return row["_Key"] or ""
                elif lvl == 2:
                    return row["_ParentKey"] or ""
                return ""
            df12["_cluster"] = df12.apply(cluster_id, axis=1)
            df12 = df12[df12["_cluster"].astype(str) != ""]
            grp = df12.groupby("_cluster", dropna=True)
            total_clusters = len(grp)
            with_artifacts = int(grp["Артефакт"].apply(lambda s: any(str(x).strip() != "" for x in s)).sum())
            coverage_pct = (with_artifacts / total_clusters) if total_clusters else 0.0
        else:
            total_clusters = 0
            with_artifacts = 0
            coverage_pct = 0.0

        coverage_rows.append({
            "Release": vname,
            "Tasks (L1 clusters)": total_clusters,
            "With artifact": with_artifacts,
            "% Coverage": coverage_pct,  # как дробь 0..1 (форматируем в Excel как %)
        })

        # Типы (для сводной по типам)
        tmp = []
        for it in issues:
            f = it.get("fields", {})
            tmp.append({
                "Release": vname,
                "Тип": (f.get("issuetype") or {}).get("name"),
                "Ключ": it.get("key"),
            })
        ov_types = pd.DataFrame(tmp)
        overview_rows_types.append(ov_types)

        # Итоговые колонки + сортировка Развитие→Сопровождение
        tree_cols = [
            "Level", "Блок", "Краткое содержание", "Задача", "Тип", "Статус",
            "Услуга", "Артефакт", "Release Note", "Исполнитель", "Fix Versions"
        ]
        df_final = tree_full[tree_cols].copy()
        order_map = {"Развитие": 0, "Сопровождение": 1}
        df_final["_bo"] = df_final["Блок"].map(order_map).fillna(2)
        df_final = df_final.sort_values(by=["_bo"], kind="stable").drop(columns=["_bo"])

        per_release.append((vname, df_final, links_df, ov_types))

    if not per_release:
        raise SystemExit("Нет задач ни в одной из подходящих версий")

    writer_path = OUT_DIR / f"release_composer_{PROJECT_KEY}_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.xlsx"
    with pd.ExcelWriter(writer_path, engine="openpyxl") as xw:
        # ----- Tree sheets -----
        for vname, tree_df, links_df, _ov in per_release:
            sheet_tree = make_sheet_name(vname, "Tree")
            tree_df.to_excel(xw, index=False, sheet_name=sheet_tree)
            ws: Worksheet = xw.sheets[sheet_tree]
            insert_legend(ws, "Блоки: Развитие — голубой; Сопровождение — жёлтый; Level 1 — светло-зелёный; Level 2 — светло-оранжевый")
            last_col_letter = get_column_letter(ws.max_column)
            ws.auto_filter.ref = f"A2:{last_col_letter}{ws.max_row}"
            ws.freeze_panes = "A3"

            for df_idx in range(len(tree_df)):
                excel_row = 3 + df_idx
                try: level_val = int(tree_df.iloc[df_idx]["Level"] or 0)
                except Exception: level_val = 0
                ws.row_dimensions[excel_row].outlineLevel = level_val
                if level_val > COLLAPSE_LEVEL:
                    ws.row_dimensions[excel_row].hidden = True

            ws.sheet_properties.outlinePr.summaryBelow = True
            ws.sheet_properties.outlinePr.applyStyles = True
            apply_wrap(ws, ["Краткое содержание", "Release Note"], header_row_idx=2)
            align_top_all(ws, header_row_idx=2)
            apply_row_styles(ws, header_row_idx=2)

        # ----- Overview -----
        if overview_rows_types:
            overview_types = pd.concat(overview_rows_types, ignore_index=True)
            pivot = pd.pivot_table(
                overview_types,
                index=["Release"],
                columns=["Тип"],
                values="Ключ",
                aggfunc="count",
                fill_value=0,
                margins=True,
            )
            pivot.to_excel(xw, sheet_name="Overview")
            ws_ov: Worksheet = xw.sheets["Overview"]
            ws_ov.auto_filter.ref = ws_ov.dimensions
            ws_ov.freeze_panes = "A2"
            # вертикальное выравнивание
            for row in ws_ov.iter_rows(min_row=1, max_row=ws_ov.max_row, min_col=1, max_col=ws_ov.max_column):
                for cell in row:
                    cell.alignment = Alignment(
                        wrap_text=cell.alignment.wrap_text,
                        horizontal=cell.alignment.horizontal,
                        vertical="top"
                    )

            # блок "Покрытие артефактами" под сводной
            start_row = ws_ov.max_row + 2
            headers = ["Release", "Tasks (L1 clusters)", "With artifact", "% Coverage"]
            for j, h in enumerate(headers, start=1):
                cell = ws_ov.cell(row=start_row, column=j, value=h)
                cell.font = Font(bold=True)
            for i, row in enumerate(coverage_rows, start=start_row + 1):
                ws_ov.cell(row=i, column=1, value=row["Release"])
                ws_ov.cell(row=i, column=2, value=row["Tasks (L1 clusters)"])
                ws_ov.cell(row=i, column=3, value=row["With artifact"])
                c = ws_ov.cell(row=i, column=4, value=row["% Coverage"])
                c.number_format = "0.0%"

    # автофит (включая Overview)
    excel_autofit_smart(writer_path, width_overrides={
        "Level": 6,
        "Блок": 16,
        "Краткое содержание": 60,
        "Задача": 16,
        "Тип": 18,
        "Статус": 16,
        "Услуга": 20,
        # "Артефакт": auto
        "Release Note": 50,
        # "Исполнитель": auto
        "Fix Versions": 28,
    })

    print(f"Готово → {writer_path}")

# ========= Aux API =========

def list_versions(project_key: str) -> List[dict]:
    if not project_key or str(project_key).strip().lower() in {"none", "null", "-", "—", "–"}:
        raise SystemExit("PROJECT_KEY пустой")
    versions = jira_get(f"{JIRA_URL}/rest/api/2/project/{project_key}/versions")
    out = []
    for v in versions:
        if VERSIONS_FILTER and v.get("name") not in VERSIONS_FILTER: continue
        if ONLY_UNRELEASED and v.get("released"): continue
        if v.get("archived"): continue
        out.append({
            "id": v.get("id"),
            "name": v.get("name"),
            "released": v.get("released"),
            "releaseDate": v.get("releaseDate"),
            "overdue": v.get("overdue"),
        })
    out.sort(key=lambda x: (x.get("releaseDate") is None,
                            x.get("releaseDate") or "9999-12-31",
                            str(x.get("name") or "")))
    if not out:
        print("[warn] Версии не найдены по фильтрам.")
    return out

def jql_search(jql: str, fields: List[str], max_results: int = 1000) -> List[dict]:
    url = f"{JIRA_URL}/rest/api/2/search"
    start_at = 0
    issues: List[dict] = []
    while True:
        payload = {"jql": jql, "startAt": start_at, "maxResults": min(100, max_results - start_at), "fields": fields}
        data = jira_post(url, payload)
        issues.extend(data.get("issues", []))
        fetched = len(data.get("issues", []))
        start_at += fetched
        if start_at >= data.get("total", 0) or start_at >= max_results or fetched == 0:
            break
    return issues

if __name__ == "__main__":
    import sys
    if len(sys.argv) >= 2:
        pk = sys.argv[1].strip()
        if pk: PROJECT_KEY = pk
    if len(sys.argv) >= 3:
        VERSIONS_FILTER = [sys.argv[2].strip()]
    main()
