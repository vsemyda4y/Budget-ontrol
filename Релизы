# -*- coding: utf-8 -*-
"""
Release Composer ‚Äî –≤—ã–≥—Ä—É–∑–∫–∞ —Å–æ—Å—Ç–∞–≤–∞ —Ä–µ–ª–∏–∑–æ–≤ –ø–æ –∫–æ–¥—É –ø—Ä–æ–µ–∫—Ç–∞ JIRA
(—ç–ø–∏–∫–∏ ‚Üí –∏—Å—Ç–æ—Ä–∏–∏/–∑–∞–¥–∞—á–∏ ‚Üí —Å–∞–±—Ç–∞—Å–∫–∏) + —Å–≤—è–∑–∏ –∑–∞–¥–∞—á ‚Üí Excel —Å –∏–µ—Ä–∞—Ä—Ö–∏–µ–π –∏ –±–∞–∑–æ–≤–æ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π.

‚öôÔ∏è –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è (–∏–ª–∏ –∑–∞–¥–∞–π—Ç–µ –ø—Ä—è–º–æ –≤ –∫–æ–¥–µ –Ω–∏–∂–µ):
- JIRA_URL            ‚Äî –±–∞–∑–æ–≤—ã–π URL –≤–∞—à–µ–π Jira (–Ω–∞–ø—Ä–∏–º–µ—Ä, https://jira.nlmk.com)
- JIRA_BEARER_TOKEN   ‚Äî Bearer-—Ç–æ–∫–µ–Ω (—Ç–æ—Ç –∂–µ, —á—Ç–æ –≤ Worklog_with_summary_labels.py)
- PROJECT_KEY         ‚Äî –∫–ª—é—á –ø—Ä–æ–µ–∫—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "CSHRM")
- VERSIONS_FILTER     ‚Äî —Å–ø–∏—Å–æ–∫ –≤–µ—Ä—Å–∏–π —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é (–∏–º–µ–Ω–∞ —Ä–µ–ª–∏–∑–æ–≤ Fix Version), –µ—Å–ª–∏ –ø—É—Å—Ç–æ ‚Äî –≤—Å–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ
- ONLY_UNRELEASED     ‚Äî "1" ‚Üí –±—Ä–∞—Ç—å —Ç–æ–ª—å–∫–æ unreleased –≤–µ—Ä—Å–∏–∏; "0" ‚Üí –≤—Å–µ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é "1")
- MAX_ISSUES          ‚Äî –∑–∞—â–∏—Ç–Ω—ã–π –ª–∏–º–∏—Ç –∑–∞–¥–∞—á –Ω–∞ –æ–¥–Ω—É –≤–µ—Ä—Å–∏—é (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 5000)

üì¶ –í—ã—Ö–æ–¥–Ω–æ–π Excel –≤–∫–ª—é—á–∞–µ—Ç –ª–∏—Å—Ç—ã:
- Overview         ‚Äî —Å–≤–æ–¥–∫–∞ –ø–æ —Ä–µ–ª–∏–∑–∞–º: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á –ø–æ —Ç–∏–ø–∞–º/—Å—Ç–∞—Ç—É—Å–∞–º
- <Release>_Tree   ‚Äî –∏–µ—Ä–∞—Ä—Ö–∏—è: Release ‚Üí Epic ‚Üí Issue ‚Üí Sub-task (—Å –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–æ–π —Å—Ç—Ä–æ–∫ –∏ HYPERLINK)
- <Release>_Links  ‚Äî —Å–ø–∏—Å–æ–∫ —Å–≤—è–∑–µ–π –∑–∞–¥–∞—á (blocks/relates/duplicates/‚Ä¶)

üß© –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ id –∫–∞—Å—Ç–æ–º-–ø–æ–ª–µ–π "Epic Link" –∏ "Story Points".
- –ò–µ—Ä–∞—Ä—Ö–∏—è —Å—Ç—Ä–æ–∏—Ç—Å—è –ø–æ –ø–æ–ª—è–º parent, subtasks –∏ epic link; –∑–∞–¥–∞—á–∏ –±–µ–∑ —ç–ø–∏–∫–∞ –≤—ã–≤–æ–¥—è—Ç—Å—è –ø–æ–¥ ¬´(–±–µ–∑ —ç–ø–∏–∫–∞)¬ª.
- –í —Å—Ç–æ–ª–±—Ü–µ ¬´–ù–æ–¥–∞¬ª –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –≤–∏–∑—É–∞–ª—å–Ω—ã–π –æ—Ç—Å—Ç—É–ø –ø–æ —É—Ä–æ–≤–Ω—é.
- –£–º–Ω—ã–π –∞–≤—Ç–æ—Ñ–∏—Ç —à–∏—Ä–∏–Ω—ã –∫–æ–ª–æ–Ω–æ–∫.

–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: requests, pandas, openpyxl
"""

import os
import re
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import pandas as pd
import requests
from openpyxl import load_workbook
from openpyxl.utils import get_column_letter
from openpyxl.worksheet.worksheet import Worksheet

# ========= ENV =========

def _env(key: str, default: Optional[str] = None) -> str:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —á—Ç–µ–Ω–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –ø—É—Å—Ç—ã—Ö/None/–¥–µ—Ñ–∏—Å–æ–≤."""
    val = os.getenv(key)
    if val is None:
        return default or ""
    val = str(val).strip()
    if val.lower() in {"none", "null", "", "-", "‚Äî", "‚Äì"}:
        return default or ""
    return val

JIRA_URL          = _env("JIRA_URL", "https://jira.nlmk.com").rstrip("/")
JIRA_BEARER_TOKEN = _env("JIRA_BEARER_TOKEN", _env("JIRA_TEMPO_TOKEN", ""))
PROJECT_KEY       = _env("PROJECT_KEY", "CSHRM")
VERSIONS_FILTER   = [v.strip() for v in _env("VERSIONS_FILTER", "").split(",") if v.strip()]
ONLY_UNRELEASED   = _env("ONLY_UNRELEASED", "1") == "1"
MAX_ISSUES        = int(_env("MAX_ISSUES", "5000"))

if not PROJECT_KEY:
    raise SystemExit("PROJECT_KEY –Ω–µ –∑–∞–¥–∞–Ω. –£–∫–∞–∂–∏ –∫–ª—é—á –ø—Ä–æ–µ–∫—Ç–∞, –Ω–∞–ø—Ä–∏–º–µ—Ä PROJECT_KEY=CSHRM")

if not JIRA_BEARER_TOKEN:
    raise SystemExit("ENV JIRA_BEARER_TOKEN/JIRA_TEMPO_TOKEN –Ω–µ –∑–∞–¥–∞–Ω ‚Äî –Ω—É–∂–µ–Ω Bearer —Ç–æ–∫–µ–Ω Jira.")

HEADERS = {
    "Authorization": f"Bearer {JIRA_BEARER_TOKEN}",
    "Accept": "application/json",
    "Content-Type": "application/json",
}

# ========= –ü–ê–ü–ö–ò –í–´–•–û–î–ê =========
OUT_DIR = Path.cwd() / "release_export"
OUT_DIR.mkdir(parents=True, exist_ok=True)

# ========= –£—Ç–∏–ª–∏—Ç—ã Excel =========

# –ò–º—è –ª–∏—Å—Ç–∞ Excel –º–∞–∫—Å–∏–º—É–º 31 —Å–∏–º–≤–æ–ª
# –ü—Ä–∏–º–µ—Ä: make_sheet_name("CSHRM 2025.10", "Tree") ‚Üí "CSHRM 2025.10_Tree" (—É—Å–µ—á—ë—Ç –±–∞–∑—É –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏)
def make_sheet_name(base: str, suffix: str) -> str:
    safe = re.sub(r'[:\\/?*\[\]]', '_', str(base or 'Release'))
    max_base = 31 - (len(suffix) + 1)  # +1 –ø–æ–¥ –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏–µ
    if max_base < 1:
        max_base = 1
    safe = safe[:max_base]
    return f"{safe}_{suffix}"

def _visible_text(val: object) -> str:
    if val is None:
        return ""
    s = str(val)
    if not s.startswith("="):
        return s
    m = re.match(r'^\s*=\s*HYPERLINK\s*\(\s*"[^"]*"\s*[,;]\s*"([^"]*)"\s*\)\s*$', s, re.IGNORECASE)
    return m.group(1) if m else s

def excel_autofit_smart(path: Path, width_overrides: Optional[Dict[str,int]] = None,
                        clamp_min: int = 6, clamp_max: int = 60):
    try:
        wb = load_workbook(path)
        for ws in wb.worksheets:
            headers = {cell.column: (cell.value or "") for cell in ws[1]}
            for col_cells in ws.columns:
                col_idx = col_cells[0].column
                head = str(headers.get(col_idx, "")).strip()
                if width_overrides and head in width_overrides:
                    ws.column_dimensions[get_column_letter(col_idx)].width = width_overrides[head]
                    continue
                max_len = max(len(_visible_text(c.value)) if c.value is not None else 0 for c in col_cells)
                max_len = max(max_len, len(head))
                ws.column_dimensions[get_column_letter(col_idx)].width = max(clamp_min, min(max_len + 2, clamp_max))
        wb.save(path)
    except Exception as e:
        print(f"[autofit] –ø—Ä–æ–ø—É—â–µ–Ω–æ: {e}")

def hyperlink_formula(key: str) -> str:
    if not key:
        return ""
    k = str(key).strip().replace('"', '""')
    return f'=HYPERLINK("{JIRA_URL}/browse/{k}","{k}")'

# ========= Jira helpers =========

SESSION = requests.Session()
SESSION.headers.update(HEADERS)

def jira_get(url: str, params: Optional[dict] = None) -> dict:
    r = SESSION.get(url, params=params, timeout=60)
    if r.status_code != 200:
        raise RuntimeError(f"GET {url} ‚Üí {r.status_code}: {r.text[:500]}")
    return r.json()

def jira_post(url: str, payload: dict) -> dict:
    r = SESSION.post(url, json=payload, timeout=120)
    if r.status_code != 200:
        raise RuntimeError(f"POST {url} ‚Üí {r.status_code}: {r.text[:500]}")
    return r.json()

def get_field_ids() -> Dict[str, str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç id –∫–∞—Å—Ç–æ–º-–ø–æ–ª–µ–π –¥–ª—è Epic Link –∏ Story Points."""
    fields = jira_get(f"{JIRA_URL}/rest/api/2/field")
    epic_link_id = None
    story_points_id = None
    for f in fields:
        name = (f.get("name") or "").strip().lower()
        fid = f.get("id")
        if name == "epic link":
            epic_link_id = fid
        if name == "story points":
            story_points_id = fid
    return {"epic_link": epic_link_id, "story_points": story_points_id}

def list_versions(project_key: str) -> List[dict]:
    if not project_key or str(project_key).strip().lower() in {"none", "null", "-", "‚Äî", "‚Äì"}:
        raise SystemExit("list_versions: –ø—É—Å—Ç–æ–π PROJECT_KEY ‚Äî –∑–∞–¥–∞–π PROJECT_KEY=CSHRM (–∏–ª–∏ —Å–≤–æ–π)")
    versions = jira_get(f"{JIRA_URL}/rest/api/2/project/{project_key}/versions")
    out = []
    for v in versions:
        if VERSIONS_FILTER and v.get("name") not in VERSIONS_FILTER:
            continue
        if ONLY_UNRELEASED and v.get("released"):
            continue
        if v.get("archived"):
            continue
        out.append({
            "id": v.get("id"),
            "name": v.get("name"),
            "released": v.get("released"),
            "releaseDate": v.get("releaseDate"),
            "overdue": v.get("overdue"),
        })
    # —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞: –ø–æ –¥–∞—Ç–µ (–ø—É—Å—Ç—ã–µ –≤ –∫–æ–Ω–µ—Ü), –∑–∞—Ç–µ–º –ø–æ –∏–º–µ–Ω–∏
    out.sort(key=lambda x: (x.get("releaseDate") is None, x.get("releaseDate") or "9999-12-31", str(x.get("name") or "")))
    if not out:
        print("[warn] –í–µ—Ä—Å–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –ø–æ –∑–∞–¥–∞–Ω–Ω—ã–º —Ñ–∏–ª—å—Ç—Ä–∞–º. –ü–æ–ø—Ä–æ–±—É–π —Å–Ω—è—Ç—å ONLY_UNRELEASED –∏–ª–∏ –∑–∞–¥–∞—Ç—å VERSIONS_FILTER.")
    return out

def jql_search(jql: str, fields: List[str], max_results: int = 1000) -> List[dict]:
    url = f"{JIRA_URL}/rest/api/2/search"
    start_at = 0
    issues: List[dict] = []
    while True:
        payload = {
            "jql": jql,
            "startAt": start_at,
            "maxResults": min(100, max_results - start_at),
            "fields": fields,
        }
        data = jira_post(url, payload)
        issues.extend(data.get("issues", []))
        fetched = len(data.get("issues", []))
        start_at += fetched
        if start_at >= data.get("total", 0) or start_at >= max_results or fetched == 0:
            break
    return issues

# ========= –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–µ—Ä–∞—Ä—Ö–∏–∏ =========

def flatten_release_tree(release_name: str, issues: List[dict], epic_link_field: Optional[str]) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """–°—Ç—Ä–æ–∏—Ç –∏–µ—Ä–∞—Ä—Ö–∏—é –∏ —Ç–∞–±–ª–∏—Ü—É —Å–≤—è–∑–µ–π –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–≥–æ —Ä–µ–ª–∏–∑–∞."""
    by_key = {i.get("key"): i for i in issues}

    def _g(obj, path: List[str]):
        for p in path:
            if obj is None:
                return None
            obj = obj.get(p) if isinstance(obj, dict) else None
        return obj

    # –∏–Ω–¥–µ–∫—Å—ã
    children: Dict[str, List[str]] = {}
    epic_children: Dict[str, List[str]] = {}
    parent_map: Dict[str, Optional[str]] = {}
    epic_of: Dict[str, Optional[str]] = {}

    # —Å–≤—è–∑–∏
    links_rows: List[dict] = []

    for k, it in by_key.items():
        fields = it.get("fields", {})
        # parent/subtasks
        parent = _g(fields, ["parent", "key"]) or None
        parent_map[k] = parent
        if parent:
            children.setdefault(parent, []).append(k)
        # epic link
        epic = fields.get(epic_link_field) if epic_link_field else None
        if isinstance(epic, dict):
            epic = epic.get("key")
        epic_of[k] = epic
        if epic:
            epic_children.setdefault(epic, []).append(k)

        # issue links
        for l in fields.get("issuelinks") or []:
            ltype = _g(l, ["type", "name"]) or ""
            inward = _g(l, ["inwardIssue", "key"]) or None
            outward = _g(l, ["outwardIssue", "key"]) or None
            if inward:
                links_rows.append({"From": k, "Direction": "inward", "Type": ltype, "To": inward})
            if outward:
                links_rows.append({"From": k, "Direction": "outward", "Type": ltype, "To": outward})

    def issue_type_name(i: dict) -> str:
        return _g(i.get("fields", {}), ["issuetype", "name"]) or ""

    def is_epic(i: dict) -> bool:
        return issue_type_name(i).lower() == "epic"

    # –∫–æ—Ä–Ω–µ–≤—ã–µ –≥—Ä—É–ø–ø—ã
    epics = [k for k, it in by_key.items() if is_epic(it)]
    roots_wo_epic = [k for k, it in by_key.items() if (k not in epics and not parent_map.get(k) and not epic_of.get(k))]

    def row_from_key(key: str, level: int, rel_name: str) -> dict:
        it = by_key[key]
        f = it.get("fields", {})
        assignee = _g(f, ["assignee", "displayName"]) or ""
        status = _g(f, ["status", "name"]) or ""
        issue_type = issue_type_name(it)
        priority = _g(f, ["priority", "name"]) or ""
        created = _g(f, ["created"]) or ""
        updated = _g(f, ["updated"]) or ""
        summary = f.get("summary") or ""
        sp_raw = f.get(STORY_POINTS_FIELD_ID) if STORY_POINTS_FIELD_ID else None
        if isinstance(sp_raw, (int, float)):
            story_points = sp_raw
        else:
            try:
                story_points = float(sp_raw) if sp_raw is not None and str(sp_raw).strip() != "" else None
            except Exception:
                story_points = None
        fix_versions = ", ".join((v.get("name") for v in (f.get("fixVersions") or [])))
        epic_key = epic_of.get(key) or (key if issue_type.lower() == "epic" else None)
        parent_key = parent_map.get(key)
        return {
            "Release": rel_name,
            "Level": level,
            "–ù–æ–¥–∞": ("  " * level) + summary,
            "–ö–ª—é—á": key,
            "–°—Å—ã–ª–∫–∞": hyperlink_formula(key),
            "–¢–∏–ø": issue_type,
            "–°—Ç–∞—Ç—É—Å": status,
            "–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å": assignee,
            "Story Points": story_points,
            "Epic": epic_key or "(–±–µ–∑ —ç–ø–∏–∫–∞)",
            "–†–æ–¥–∏—Ç–µ–ª—å": parent_key or "",
            "Priority": priority,
            "Fix Version(s)": fix_versions,
            "Created": created,
            "Updated": updated,
        }

    rows: List[dict] = []

    def walk_issue(key: str, level: int):
        rows.append(row_from_key(key, level, release_name))
        for ch in children.get(key, []):
            walk_issue(ch, level + 1)

    # 1) –≠–ø–∏–∫–∏
    for e in sorted(epics):
        rows.append(row_from_key(e, 0, release_name))
        for k in sorted(set(epic_children.get(e, []))):
            # –µ—Å–ª–∏ —É story –µ—Å—Ç—å —Ä–æ–¥–∏—Ç–µ–ª—å –Ω–µ-—ç–ø–∏–∫ ‚Äî –≤—Å—ë —Ä–∞–≤–Ω–æ –æ–±–æ–π–¥—ë–º –¥–µ—Ä–µ–≤–æ–º parent
            walk_issue(k, 1)

    # 2) –ë–µ–∑ —ç–ø–∏–∫–∞ –∏ –±–µ–∑ —Ä–æ–¥–∏—Ç–µ–ª—è ‚Äî –≤–µ—Ä—Ö–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å
    if roots_wo_epic:
        rows.append({
            "Release": release_name,
            "Level": 0,
            "–ù–æ–¥–∞": "(–±–µ–∑ —ç–ø–∏–∫–∞)",
            "–ö–ª—é—á": "",
            "–°—Å—ã–ª–∫–∞": "",
            "–¢–∏–ø": "",
            "–°—Ç–∞—Ç—É—Å": "",
            "–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å": "",
            "Story Points": None,
            "Epic": "(–±–µ–∑ —ç–ø–∏–∫–∞)",
            "–†–æ–¥–∏—Ç–µ–ª—å": "",
            "Priority": "",
            "Fix Version(s)": "",
            "Created": "",
            "Updated": "",
        })
        for k in sorted(roots_wo_epic):
            walk_issue(k, 1)

    tree_df = pd.DataFrame(rows)
    links_df = pd.DataFrame(links_rows) if links_rows else pd.DataFrame(columns=["From","Direction","Type","To"])
    return tree_df, links_df

# ========= –û—Å–Ω–æ–≤–Ω–æ–π —Å—Ü–µ–Ω–∞—Ä–∏–π =========

FIELDS_CACHE = None
EPIC_LINK_FIELD_ID = None
STORY_POINTS_FIELD_ID = None

def main():
    global FIELDS_CACHE, EPIC_LINK_FIELD_ID, STORY_POINTS_FIELD_ID

    # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø–µ—Ä–µ–¥ —Å—Ç–∞—Ä—Ç–æ–º
    print("=== Release Composer: —Å—Ç–∞—Ä—Ç ===")
    print(f"JIRA_URL        : {JIRA_URL}")
    print(f"PROJECT_KEY     : {PROJECT_KEY}")
    print(f"ONLY_UNRELEASED : {ONLY_UNRELEASED}")
    print(f"VERSIONS_FILTER : {', '.join(VERSIONS_FILTER) if VERSIONS_FILTER else '(–≤—Å–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ)'}")

    print("‚Üí –ü–æ–ª—É—á–∞—é —Å–ø–∏—Å–æ–∫ –≤–µ—Ä—Å–∏–π...")
    versions = list_versions(PROJECT_KEY)
    if not versions:
        raise SystemExit("–ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –≤–µ—Ä—Å–∏–π (–ø—Ä–æ–≤–µ—Ä—å —Ñ–∏–ª—å—Ç—Ä—ã/–ø—Ä–∞–≤–∞)")

    # –û–ø—Ä–µ–¥–µ–ª–∏–º id –∫–∞—Å—Ç–æ–º-–ø–æ–ª–µ–π
    ids = get_field_ids()
    EPIC_LINK_FIELD_ID = ids.get("epic_link")
    STORY_POINTS_FIELD_ID = ids.get("story_points")
    if not EPIC_LINK_FIELD_ID:
        print("[warn] –ù–µ –Ω–∞—à—ë–ª id 'Epic Link' ‚Äî –∏–µ—Ä–∞—Ä—Ö–∏—è –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–ø–æ–ª–Ω–æ–π")

    # –ö–∞–∫–∏–µ –ø–æ–ª—è –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º
    fields = [
        "summary", "issuetype", "status", "assignee", "parent",
        "subtasks", "issuelinks", "priority", "fixVersions", "created", "updated",
    ]
    if EPIC_LINK_FIELD_ID:
        fields.append(EPIC_LINK_FIELD_ID)
    if STORY_POINTS_FIELD_ID:
        fields.append(STORY_POINTS_FIELD_ID)

    writer_path = OUT_DIR / f"release_composer_{PROJECT_KEY}_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.xlsx"
    overview_rows: List[pd.DataFrame] = []

    with pd.ExcelWriter(writer_path, engine="openpyxl") as xw:

        for v in versions:
            vname = v.get("name")
            print(f"‚Üí –í–µ—Ä—Å–∏—è: {vname}")
            jql = f'project={PROJECT_KEY} AND fixVersion="{vname}" ORDER BY issuetype, key'
            issues = jql_search(jql, fields, max_results=MAX_ISSUES)
            if not issues:
                print("  (–Ω–µ—Ç –∑–∞–¥–∞—á)")
                continue

            # –°–≤–æ–¥–∫–∞ –ø–æ —Ç–∏–ø–∞–º/—Å—Ç–∞—Ç—É—Å–∞–º
            tmp = []
            for it in issues:
                f = it.get("fields", {})
                tmp.append({
                    "Release": vname,
                    "–¢–∏–ø": (f.get("issuetype") or {}).get("name"),
                    "–°—Ç–∞—Ç—É—Å": (f.get("status") or {}).get("name"),
                    "–ö–ª—é—á": it.get("key"),
                })
            ov = pd.DataFrame(tmp)
            overview_rows.append(ov)

            # –ò–µ—Ä–∞—Ä—Ö–∏—è
            tree_df, links_df = flatten_release_tree(vname, issues, EPIC_LINK_FIELD_ID)

            # –ü–æ—Ä—è–¥–æ–∫ –∫–æ–ª–æ–Ω–æ–∫
            tree_cols = [
                "Release","Level","–ù–æ–¥–∞","–ö–ª—é—á","–°—Å—ã–ª–∫–∞","–¢–∏–ø","–°—Ç–∞—Ç—É—Å","–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å",
                "Story Points","Epic","–†–æ–¥–∏—Ç–µ–ª—å","Priority","Fix Version(s)","Created","Updated"
            ]
            tree_df = tree_df[tree_cols]

            # –°–æ–∑–¥–∞–Ω–∏–µ –ª–∏—Å—Ç–∞ –¥–ª—è –¥–µ—Ä–µ–≤–∞
            sheet_tree = make_sheet_name(vname, "Tree")
            tree_df.to_excel(xw, index=False, sheet_name=sheet_tree)

            # –ü–æ–ª—É—á–∞–µ–º —Å–∞–º –ª–∏—Å—Ç openpyxl
            ws: Worksheet = xw.sheets[sheet_tree]

            # –£—Ä–æ–≤–Ω–∏ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ —Å—Ç—Ä–æ–∫
            for i in range(2, ws.max_row + 1):  # –±–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞
                try:
                    level_val = tree_df.iloc[i - 2]["Level"] or 0
                except Exception:
                    level_val = 0
                ws.row_dimensions[i].outlineLevel = int(level_val)
            ws.sheet_properties.outlinePr.summaryBelow = True
            ws.sheet_properties.outlinePr.applyStyles = True
            ws.auto_filter.ref = ws.dimensions
            ws.freeze_panes = "A2"

            # –°–≤—è–∑–∏ –∑–∞–¥–∞—á
            if not links_df.empty:
                sheet_links = make_sheet_name(vname, "Links")
                links_df.to_excel(xw, index=False, sheet_name=sheet_links)
                ws2: Worksheet = xw.sheets[sheet_links]
                ws2.auto_filter.ref = ws2.dimensions
                ws2.freeze_panes = "A2"

        # –ò—Ç–æ–≥–æ–≤—ã–π Overview
        if overview_rows:
            overview = pd.concat(overview_rows, ignore_index=True)
            pivot = pd.pivot_table(
                overview,
                index=["Release", "–¢–∏–ø"],
                columns=["–°—Ç–∞—Ç—É—Å"],
                values="–ö–ª—é—á",
                aggfunc="count",
                fill_value=0,
                margins=True,
            )
            pivot.to_excel(xw, sheet_name="Overview")
            ws_ov: Worksheet = xw.sheets["Overview"]
            ws_ov.auto_filter.ref = ws_ov.dimensions
            ws_ov.freeze_panes = "A2"

    # –ê–≤—Ç–æ—Ñ–∏—Ç —à–∏—Ä–∏–Ω—ã
    excel_autofit_smart(writer_path, width_overrides={
        "–ù–æ–¥–∞": 60,
        "–°—Å—ã–ª–∫–∞": 16,
        "–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å": 28,
        "Fix Version(s)": 28,
        "Priority": 12,
    })

    print(f"–ì–æ—Ç–æ–≤–æ ‚Üí {writer_path}")

if __name__ == "__main__":
    # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∏–∑ –∫–æ–Ω—Å–æ–ª–∏ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏: python Release.py CSHRM "Rel 2025.10"
    import sys
    if len(sys.argv) >= 2:
        pk = sys.argv[1].strip()
        if pk:
            PROJECT_KEY = pk
    if len(sys.argv) >= 3:
        VERSIONS_FILTER = [sys.argv[2].strip()]
    main()
