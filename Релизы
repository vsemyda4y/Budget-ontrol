# -*- coding: utf-8 -*-
"""
Release Composer ‚Äî –≤—ã–≥—Ä—É–∑–∫–∞ —Å–æ—Å—Ç–∞–≤–∞ —Ä–µ–ª–∏–∑–æ–≤ –ø–æ –∫–æ–¥—É –ø—Ä–æ–µ–∫—Ç–∞ JIRA
(—ç–ø–∏–∫–∏ ‚Üí –∏—Å—Ç–æ—Ä–∏–∏/–∑–∞–¥–∞—á–∏ ‚Üí —Å–∞–±—Ç–∞—Å–∫–∏) + —Å–≤—è–∑–∏ –∑–∞–¥–∞—á (–≤ —Ç.—á. –≤–∏—Ä—Ç—É–∞–ª—å–Ω–∞—è –∏–µ—Ä–∞—Ä—Ö–∏—è –ø–æ —Ç–∏–ø–∞–º) ‚Üí Excel c –∏–µ—Ä–∞—Ä—Ö–∏–µ–π.

‚öôÔ∏è –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è (–º–æ–∂–Ω–æ –∑–∞–¥–∞—Ç—å –≤ –∫–æ–¥–µ –Ω–∏–∂–µ):
- JIRA_URL            ‚Äî –±–∞–∑–æ–≤—ã–π URL Jira (–Ω–∞–ø—Ä–∏–º–µ—Ä, https://jira.nlmk.com)
- JIRA_BEARER_TOKEN   ‚Äî Bearer-—Ç–æ–∫–µ–Ω (–º–æ–∂–Ω–æ —Ç–æ—Ç –∂–µ, —á—Ç–æ –≤ Worklog_with_summary_labels.py)
- PROJECT_KEY         ‚Äî –∫–ª—é—á –ø—Ä–æ–µ–∫—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "CSHRM")
- VERSIONS_FILTER     ‚Äî —Å–ø–∏—Å–æ–∫ –∏–º—ë–Ω –≤–µ—Ä—Å–∏–π —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é (Fix Version). –ï—Å–ª–∏ –ø—É—Å—Ç–æ ‚Äî –±–µ—Ä—ë–º –≤—Å–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ.
- ONLY_UNRELEASED     ‚Äî "1" ‚Üí —Ç–æ–ª—å–∫–æ unreleased –≤–µ—Ä—Å–∏–∏; "0" ‚Üí –≤—Å–µ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é "1")
- MAX_ISSUES          ‚Äî –∑–∞—â–∏—Ç–Ω—ã–π –ª–∏–º–∏—Ç –∑–∞–¥–∞—á –Ω–∞ –æ–¥–Ω—É –≤–µ—Ä—Å–∏—é (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 5000)
- ENABLE_LINK_HIERARCHY ‚Äî "1" ‚Üí —Å—Ç—Ä–æ–∏—Ç—å –≤–∏—Ä—Ç—É–∞–ª—å–Ω—É—é –∏–µ—Ä–∞—Ä—Ö–∏—é –ø–æ –ª–∏–Ω–∫–∞–º (—Å–º. LINK_HIERARCHY_RULES), –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é "1"
- CONFLUENCE_HOST     ‚Äî –ø–æ–¥—Å—Ç—Ä–æ–∫–∞ —Ö–æ—Å—Ç–∞ Confluence –¥–ª—è –ø–æ–∏—Å–∫–∞ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é "confluence")

üì¶ –í—ã—Ö–æ–¥–Ω–æ–π Excel:
- –¢–æ–ª—å–∫–æ –ª–∏—Å—Ç—ã <Release>_Tree ‚Äî –∏–µ—Ä–∞—Ä—Ö–∏—è –¥–ª—è –∫–∞–∂–¥–æ–π –≤–µ—Ä—Å–∏–∏.
- Overview ‚Äî —Å–≤–æ–¥–Ω–∞—è –ø–æ —Ç–∏–ø–∞–º/—Å—Ç–∞—Ç—É—Å–∞–º (–æ—Å—Ç–∞–≤–∏–ª; —Å–∫–∞–∂–µ—à—å ‚Äî —É–±–µ—Ä—É).

–ö–æ–ª–æ–Ω–∫–∏ –Ω–∞ –ª–∏—Å—Ç–∞—Ö ..._Tree:
Level, –ù–æ–¥–∞, –°—Å—ã–ª–∫–∞, –ê—Ä—Ç–µ—Ñ–∞–∫—Ç, –¢–∏–ø, –°—Ç–∞—Ç—É—Å, –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å, Story Points, Priority, Fix Version(s), Created, Updated
"""

import os
import re
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import pandas as pd
import requests
from openpyxl import load_workbook
from openpyxl.utils import get_column_letter
from openpyxl.worksheet.worksheet import Worksheet

# ========= ENV =========

def _env(key: str, default: Optional[str] = None) -> str:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —á—Ç–µ–Ω–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –ø—É—Å—Ç—ã—Ö/None/–¥–µ—Ñ–∏—Å–æ–≤."""
    val = os.getenv(key)
    if val is None:
        return default or ""
    val = str(val).strip()
    if val.lower() in {"none", "null", "", "-", "‚Äî", "‚Äì"}:
        return default or ""
    return val

JIRA_URL              = _env("JIRA_URL", "https://jira.nlmk.com").rstrip("/")
JIRA_BEARER_TOKEN     = _env("JIRA_BEARER_TOKEN", _env("JIRA_TEMPO_TOKEN", ""))
PROJECT_KEY           = _env("PROJECT_KEY", "CSHRM")
VERSIONS_FILTER       = [v.strip() for v in _env("VERSIONS_FILTER", "").split(",") if v.strip()]
ONLY_UNRELEASED       = _env("ONLY_UNRELEASED", "1") == "1"
MAX_ISSUES            = int(_env("MAX_ISSUES", "5000"))
ENABLE_LINK_HIERARCHY = _env("ENABLE_LINK_HIERARCHY", "1") == "1"
CONFLUENCE_HOST       = _env("CONFLUENCE_HOST", "confluence")

if not PROJECT_KEY:
    raise SystemExit("PROJECT_KEY –Ω–µ –∑–∞–¥–∞–Ω. –£–∫–∞–∂–∏ –∫–ª—é—á –ø—Ä–æ–µ–∫—Ç–∞, –Ω–∞–ø—Ä–∏–º–µ—Ä PROJECT_KEY=CSHRM")

if not JIRA_BEARER_TOKEN:
    raise SystemExit("ENV JIRA_BEARER_TOKEN/JIRA_TEMPO_TOKEN –Ω–µ –∑–∞–¥–∞–Ω ‚Äî –Ω—É–∂–µ–Ω Bearer —Ç–æ–∫–µ–Ω Jira.")

HEADERS = {
    "Authorization": f"Bearer {JIRA_BEARER_TOKEN}",
    "Accept": "application/json",
    "Content-Type": "application/json",
}

# ========= –ü–ê–ü–ö–ò –í–´–•–û–î–ê =========
OUT_DIR = Path.cwd() / "release_export"
OUT_DIR.mkdir(parents=True, exist_ok=True)

# ========= –£—Ç–∏–ª–∏—Ç—ã Excel =========

# –ò–º—è –ª–∏—Å—Ç–∞ Excel –º–∞–∫—Å–∏–º—É–º 31 —Å–∏–º–≤–æ–ª, —á–∏—Å—Ç–∏–º –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ –∑–Ω–∞–∫–∏
def make_sheet_name(base: str, suffix: str) -> str:
    safe = re.sub(r'[:\\/?*\[\]]', '_', str(base or 'Release'))
    max_base = 31 - (len(suffix) + 1)  # +1 –ø–æ–¥ "_"
    if max_base < 1:
        max_base = 1
    safe = safe[:max_base]
    return f"{safe}_{suffix}"

def _visible_text(val: object) -> str:
    if val is None:
        return ""
    s = str(val)
    if not s.startswith("="):
        return s
    m = re.match(r'^\s*=\s*HYPERLINK\s*\(\s*"[^"]*"\s*[,;]\s*"([^"]*)"\s*\)\s*$', s, re.IGNORECASE)
    return m.group(1) if m else s

def excel_autofit_smart(path: Path, width_overrides: Optional[Dict[str,int]] = None,
                        clamp_min: int = 6, clamp_max: int = 60):
    try:
        wb = load_workbook(path)
        for ws in wb.worksheets:
            headers = {cell.column: (cell.value or "") for cell in ws[1]}
            for col_cells in ws.columns:
                col_idx = col_cells[0].column
                head = str(headers.get(col_idx, "")).strip()
                if width_overrides and head in width_overrides:
                    ws.column_dimensions[get_column_letter(col_idx)].width = width_overrides[head]
                    continue
                max_len = max(len(_visible_text(c.value)) if c.value is not None else 0 for c in col_cells)
                max_len = max(max_len, len(head))
                ws.column_dimensions[get_column_letter(col_idx)].width = max(clamp_min, min(max_len + 2, clamp_max))
        wb.save(path)
    except Exception as e:
        print(f"[autofit] –ø—Ä–æ–ø—É—â–µ–Ω–æ: {e}")

def hyperlink_formula(key: str) -> str:
    if not key:
        return ""
    k = str(key).strip().replace('"', '""')
    return f'=HYPERLINK("{JIRA_URL}/browse/{k}","{k}")'

# ========= Jira helpers =========

SESSION = requests.Session()
SESSION.headers.update(HEADERS)

def jira_get(url: str, params: Optional[dict] = None) -> dict:
    r = SESSION.get(url, params=params, timeout=60)
    if r.status_code != 200:
        raise RuntimeError(f"GET {url} ‚Üí {r.status_code}: {r.text[:500]}")
    return r.json()

def jira_post(url: str, payload: dict) -> dict:
    r = SESSION.post(url, json=payload, timeout=120)
    if r.status_code != 200:
        raise RuntimeError(f"POST {url} ‚Üí {r.status_code}: {r.text[:500]}")
    return r.json()

def get_field_ids() -> Dict[str, str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç id –∫–∞—Å—Ç–æ–º-–ø–æ–ª–µ–π –¥–ª—è Epic Link –∏ Story Points."""
    fields = jira_get(f"{JIRA_URL}/rest/api/2/field")
    epic_link_id = None
    story_points_id = None
    for f in fields:
        name = (f.get("name") or "").strip().lower()
        fid = f.get("id")
        if name == "epic link":
            epic_link_id = fid
        if name == "story points":
            story_points_id = fid
    return {"epic_link": epic_link_id, "story_points": story_points_id}

def list_versions(project_key: str) -> List[dict]:
    if not project_key or str(project_key).strip().lower() in {"none", "null", "-", "‚Äî", "‚Äì"}:
        raise SystemExit("list_versions: –ø—É—Å—Ç–æ–π PROJECT_KEY ‚Äî –∑–∞–¥–∞–π PROJECT_KEY=CSHRM (–∏–ª–∏ —Å–≤–æ–π)")
    versions = jira_get(f"{JIRA_URL}/rest/api/2/project/{project_key}/versions")
    out = []
    for v in versions:
        if VERSIONS_FILTER and v.get("name") not in VERSIONS_FILTER:
            continue
        if ONLY_UNRELEASED and v.get("released"):
            continue
        if v.get("archived"):
            continue
        out.append({
            "id": v.get("id"),
            "name": v.get("name"),
            "released": v.get("released"),
            "releaseDate": v.get("releaseDate"),
            "overdue": v.get("overdue"),
        })
    out.sort(key=lambda x: (x.get("releaseDate") is None, x.get("releaseDate") or "9999-12-31", str(x.get("name") or "")))
    if not out:
        print("[warn] –í–µ—Ä—Å–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –ø–æ –∑–∞–¥–∞–Ω–Ω—ã–º —Ñ–∏–ª—å—Ç—Ä–∞–º. –ü–æ–ø—Ä–æ–±—É–π —Å–Ω—è—Ç—å ONLY_UNRELEASED –∏–ª–∏ –∑–∞–¥–∞—Ç—å VERSIONS_FILTER.")
    return out

def jql_search(jql: str, fields: List[str], max_results: int = 1000) -> List[dict]:
    url = f"{JIRA_URL}/rest/api/2/search"
    start_at = 0
    issues: List[dict] = []
    while True:
        payload = {
            "jql": jql,
            "startAt": start_at,
            "maxResults": min(100, max_results - start_at),
            "fields": fields,
        }
        data = jira_post(url, payload)
        issues.extend(data.get("issues", []))
        fetched = len(data.get("issues", []))
        start_at += fetched
        if start_at >= data.get("total", 0) or start_at >= max_results or fetched == 0:
            break
    return issues

def get_confluence_artifact(issue_key: str) -> str:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ñ–æ—Ä–º—É–ª—É Excel HYPERLINK –Ω–∞ –ø–µ—Ä–≤—É—é Confluence-—Å—Å—ã–ª–∫—É –∏–∑ remotelink –∑–∞–¥–∞—á–∏.
    –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É.
    """
    try:
        arr = jira_get(f"{JIRA_URL}/rest/api/2/issue/{issue_key}/remotelink")
    except Exception:
        return ""
    host = CONFLUENCE_HOST.lower().strip()
    for rl in arr or []:
        obj = (rl or {}).get("object") or {}
        url = (obj.get("url") or "").strip()
        title = (obj.get("title") or "Confluence").strip()
        if url and (host in url.lower()):
            u = url.replace('"', '""')
            t = title.replace('"', '""')
            return f'=HYPERLINK("{u}","{t}")'
    return ""

# ========= –ò–µ—Ä–∞—Ä—Ö–∏—è –ø–æ –ª–∏–Ω–∫–∞–º =========
# –ü—Ä–∞–≤–∏–ª–∞ "–≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–π" –∏–µ—Ä–∞—Ä—Ö–∏–∏ –ø–æ —Å—Å—ã–ª–∫–∞–º: parent_type ‚Üí child_type (case-insensitive)
LINK_HIERARCHY_RULES = [
    ("engineering concept", "change request"),
    ("support", "bugfix"),
]

# ========= –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–µ—Ä–∞—Ä—Ö–∏–∏ =========

def flatten_release_tree(release_name: str, issues: List[dict], epic_link_field: Optional[str]) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """–°—Ç—Ä–æ–∏—Ç –∏–µ—Ä–∞—Ä—Ö–∏—é –∏ —Ç–∞–±–ª–∏—Ü—É —Å–≤—è–∑–µ–π –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–≥–æ —Ä–µ–ª–∏–∑–∞.
    –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: –µ—Å–ª–∏ ENABLE_LINK_HIERARCHY=1 ‚Äî —Å–æ–∑–¥–∞—ë—Ç –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–µ —Å–≤—è–∑–∏ parent‚Üíchild –ø–æ —Ç–∏–ø–∞–º –∑–∞–¥–∞—á —Å–æ–≥–ª–∞—Å–Ω–æ LINK_HIERARCHY_RULES.
    """
    by_key = {i.get("key"): i for i in issues}

    def _g(obj, path: List[str]):
        for p in path:
            if obj is None:
                return None
            obj = obj.get(p) if isinstance(obj, dict) else None
        return obj

    # –∏–Ω–¥–µ–∫—Å—ã
    children: Dict[str, List[str]] = {}
    epic_children: Dict[str, List[str]] = {}
    parent_map: Dict[str, Optional[str]] = {}
    epic_of: Dict[str, Optional[str]] = {}

    # —Å–≤—è–∑–∏
    links_rows: List[dict] = []
    link_pairs: List[Tuple[str, str]] = []

    def issue_type_name(i: dict) -> str:
        return _g(i.get("fields", {}), ["issuetype", "name"]) or ""

    for k, it in by_key.items():
        fields = it.get("fields", {})
        # parent/subtasks
        parent = _g(fields, ["parent", "key"]) or None
        parent_map[k] = parent
        if parent:
            children.setdefault(parent, []).append(k)
        # epic link
        epic = fields.get(epic_link_field) if epic_link_field else None
        if isinstance(epic, dict):
            epic = epic.get("key")
        epic_of[k] = epic
        if epic:
            epic_children.setdefault(epic, []).append(k)
        # issue links (—Å–æ–±–∏—Ä–∞–µ–º –ø–∞—Ä—ã)
        for l in fields.get("issuelinks") or []:
            ltype = _g(l, ["type", "name"]) or ""
            inward = _g(l, ["inwardIssue", "key"]) or None
            outward = _g(l, ["outwardIssue", "key"]) or None
            if inward:
                links_rows.append({"From": k, "Direction": "inward", "Type": ltype, "To": inward})
                link_pairs.append((k, inward))
            if outward:
                links_rows.append({"From": k, "Direction": "outward", "Type": ltype, "To": outward})
                link_pairs.append((k, outward))

    # –ö–µ—à Confluence-–∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
    _artifact_cache: Dict[str, str] = {}
    def artifact_for(key: str) -> str:
        if key not in _artifact_cache:
            _artifact_cache[key] = get_confluence_artifact(key)
        return _artifact_cache[key]

    # –í–∏—Ä—Ç—É–∞–ª—å–Ω–∞—è –∏–µ—Ä–∞—Ä—Ö–∏—è –ø–æ —Å—Å—ã–ª–∫–∞–º
    if ENABLE_LINK_HIERARCHY and LINK_HIERARCHY_RULES:
        rules = [(a.lower(), b.lower()) for a, b in LINK_HIERARCHY_RULES]
        for a, b in link_pairs:
            ia = by_key.get(a); ib = by_key.get(b)
            if not ia or not ib:
                continue
            ta = issue_type_name(ia).lower(); tb = issue_type_name(ib).lower()
            # A ‚Üí B
            if (ta, tb) in rules:
                if not parent_map.get(b) and not epic_of.get(b):
                    parent_map[b] = a
                    children.setdefault(a, []).append(b)
            # B ‚Üí A
            if (tb, ta) in rules:
                if not parent_map.get(a) and not epic_of.get(a):
                    parent_map[a] = b
                    children.setdefault(b, []).append(a)

    # –∫–æ—Ä–Ω–µ–≤—ã–µ –≥—Ä—É–ø–ø—ã
    epics = [k for k, it in by_key.items() if issue_type_name(it).lower() == "epic"]
    roots_wo_epic = [k for k, it in by_key.items() if (k not in epics and not parent_map.get(k) and not epic_of.get(k))]

    def row_from_key(key: str, level: int, rel_name: str) -> dict:
        it = by_key[key]
        f = it.get("fields", {})
        assignee = _g(f, ["assignee", "displayName"]) or ""
        status = _g(f, ["status", "name"]) or ""
        issue_type = issue_type_name(it)
        priority = _g(f, ["priority", "name"]) or ""
        created = _g(f, ["created"]) or ""
        updated = _g(f, ["updated"]) or ""
        summary = f.get("summary") or ""
        sp_raw = f.get(STORY_POINTS_FIELD_ID) if STORY_POINTS_FIELD_ID else None
        if isinstance(sp_raw, (int, float)):
            story_points = sp_raw
        else:
            try:
                story_points = float(sp_raw) if sp_raw is not None and str(sp_raw).strip() != "" else None
            except Exception:
                story_points = None
        fix_versions = ", ".join((v.get("name") for v in (f.get("fixVersions") or [])))
        # parent_key = parent_map.get(key)  # —Ç–µ—Ö. –ø–æ–ª–µ ‚Äî –≤ –≤—ã–≤–æ–¥–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º
        return {
            "Release": rel_name,  # —Ç–µ—Ö. –ø–æ–ª–µ ‚Äî –Ω–µ –≤—ã–≤–æ–¥–∏–º
            "Level": level,
            "–ù–æ–¥–∞": ("  " * level) + summary,
            "–°—Å—ã–ª–∫–∞": hyperlink_formula(key),
            "–ê—Ä—Ç–µ—Ñ–∞–∫—Ç": artifact_for(key),
            "–¢–∏–ø": issue_type,
            "–°—Ç–∞—Ç—É—Å": status,
            "–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å": assignee,
            "Story Points": story_points,
            "Priority": priority,
            "Fix Version(s)": fix_versions,
            "Created": created,
            "Updated": updated,
        }

    rows: List[dict] = []

    def walk_issue(key: str, level: int):
        rows.append(row_from_key(key, level, release_name))
        for ch in children.get(key, []):
            walk_issue(ch, level + 1)

    # 1) –≠–ø–∏–∫–∏ ‚Üí –∏—Ö –¥–µ—Ç–∏
    for e in sorted(epics):
        rows.append(row_from_key(e, 0, release_name))
        for k in sorted(set(children.get(e, []) + epic_children.get(e, []))):
            walk_issue(k, 1)

    # 2) –ë–µ–∑ —ç–ø–∏–∫–∞ –∏ –±–µ–∑ —Ä–æ–¥–∏—Ç–µ–ª—è ‚Äî –≤–µ—Ä—Ö–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å
    if roots_wo_epic:
        rows.append({
            "Release": release_name,
            "Level": 0,
            "–ù–æ–¥–∞": "(–±–µ–∑ —ç–ø–∏–∫–∞)",
            "–°—Å—ã–ª–∫–∞": "",
            "–ê—Ä—Ç–µ—Ñ–∞–∫—Ç": "",
            "–¢–∏–ø": "",
            "–°—Ç–∞—Ç—É—Å": "",
            "–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å": "",
            "Story Points": None,
            "Priority": "",
            "Fix Version(s)": "",
            "Created": "",
            "Updated": "",
        })
        for k in sorted(roots_wo_epic):
            walk_issue(k, 1)

    tree_df = pd.DataFrame(rows)
    links_df = pd.DataFrame(links_rows) if links_rows else pd.DataFrame(columns=["From","Direction","Type","To"])
    return tree_df, links_df

# ========= –û—Å–Ω–æ–≤–Ω–æ–π —Å—Ü–µ–Ω–∞—Ä–∏–π =========

EPIC_LINK_FIELD_ID = None
STORY_POINTS_FIELD_ID = None

def main():
    global EPIC_LINK_FIELD_ID, STORY_POINTS_FIELD_ID

    # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø–µ—Ä–µ–¥ —Å—Ç–∞—Ä—Ç–æ–º
    print("=== Release Composer: —Å—Ç–∞—Ä—Ç ===")
    print(f"JIRA_URL              : {JIRA_URL}")
    print(f"PROJECT_KEY           : {PROJECT_KEY}")
    print(f"ONLY_UNRELEASED       : {ONLY_UNRELEASED}")
    print(f"VERSIONS_FILTER       : {', '.join(VERSIONS_FILTER) if VERSIONS_FILTER else '(–≤—Å–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ)'}")
    print(f"ENABLE_LINK_HIERARCHY : {ENABLE_LINK_HIERARCHY}")
    print(f"CONFLUENCE_HOST       : {CONFLUENCE_HOST}")

    print("‚Üí –ü–æ–ª—É—á–∞—é —Å–ø–∏—Å–æ–∫ –≤–µ—Ä—Å–∏–π...")
    versions = list_versions(PROJECT_KEY)
    if not versions:
        raise SystemExit("–ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –≤–µ—Ä—Å–∏–π (–ø—Ä–æ–≤–µ—Ä—å —Ñ–∏–ª—å—Ç—Ä—ã/–ø—Ä–∞–≤–∞)")

    # –û–ø—Ä–µ–¥–µ–ª–∏–º id –∫–∞—Å—Ç–æ–º-–ø–æ–ª–µ–π
    ids = get_field_ids()
    EPIC_LINK_FIELD_ID = ids.get("epic_link")
    STORY_POINTS_FIELD_ID = ids.get("story_points")
    if not EPIC_LINK_FIELD_ID:
        print("[warn] –ù–µ –Ω–∞—à—ë–ª id 'Epic Link' ‚Äî –∏–µ—Ä–∞—Ä—Ö–∏—è –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–ø–æ–ª–Ω–æ–π")

    # –ü–æ–ª—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
    fields = [
        "summary", "issuetype", "status", "assignee", "parent",
        "subtasks", "issuelinks", "priority", "fixVersions", "created", "updated",
    ]
    if EPIC_LINK_FIELD_ID:
        fields.append(EPIC_LINK_FIELD_ID)
    if STORY_POINTS_FIELD_ID:
        fields.append(STORY_POINTS_FIELD_ID)

    per_release = []  # [(vname, tree_df, links_df, ov_df)]
    overview_rows: List[pd.DataFrame] = []

    for v in versions:
        vname = v.get("name")
        print(f"‚Üí –í–µ—Ä—Å–∏—è: {vname}")
        jql = f'project={PROJECT_KEY} AND fixVersion="{vname}" ORDER BY issuetype, key'
        issues = jql_search(jql, fields, max_results=MAX_ISSUES)
        if not issues:
            print("  (–Ω–µ—Ç –∑–∞–¥–∞—á)")
            continue

        # –°–≤–æ–¥–∫–∞
        tmp = []
        for it in issues:
            f = it.get("fields", {})
            tmp.append({
                "Release": vname,
                "–¢–∏–ø": (f.get("issuetype") or {}).get("name"),
                "–°—Ç–∞—Ç—É—Å": (f.get("status") or {}).get("name"),
                "–ö–ª—é—á": it.get("key"),
            })
        ov = pd.DataFrame(tmp)
        overview_rows.append(ov)

        # –ò–µ—Ä–∞—Ä—Ö–∏—è (—Å —É—á—ë—Ç–æ–º LINK_HIERARCHY_RULES)
        tree_df, links_df = flatten_release_tree(vname, issues, EPIC_LINK_FIELD_ID)
        # –ò—Ç–æ–≥–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –≤—ã–¥–∞—á–∏
        tree_cols = [
            "Level", "–ù–æ–¥–∞", "–°—Å—ã–ª–∫–∞", "–ê—Ä—Ç–µ—Ñ–∞–∫—Ç", "–¢–∏–ø", "–°—Ç–∞—Ç—É—Å", "–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å",
            "Story Points", "Priority", "Fix Version(s)", "Created", "Updated"
        ]
        tree_df = tree_df[tree_cols]
        per_release.append((vname, tree_df, links_df, ov))

    if not per_release:
        raise SystemExit("–ù–µ—Ç –∑–∞–¥–∞—á –Ω–∏ –≤ –æ–¥–Ω–æ–π –∏–∑ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –≤–µ—Ä—Å–∏–π")

    writer_path = OUT_DIR / f"release_composer_{PROJECT_KEY}_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.xlsx"
    with pd.ExcelWriter(writer_path, engine="openpyxl") as xw:
        # –¢–æ–ª—å–∫–æ Tree-–≤–∫–ª–∞–¥–∫–∏ –ø–æ –∫–∞–∂–¥–æ–π –≤–µ—Ä—Å–∏–∏
        for vname, tree_df, links_df, _ov in per_release:
            sheet_tree = make_sheet_name(vname, "Tree")
            tree_df.to_excel(xw, index=False, sheet_name=sheet_tree)
            ws: Worksheet = xw.sheets[sheet_tree]
            # –£—Ä–æ–≤–Ω–∏ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ —Å—Ç—Ä–æ–∫ –ø–æ –∫–æ–ª–æ–Ω–∫–µ Level
            for i in range(2, ws.max_row + 1):  # –±–µ–∑ —à–∞–ø–∫–∏
                try:
                    level_val = int(tree_df.iloc[i - 2]["Level"] or 0)
                except Exception:
                    level_val = 0
                ws.row_dimensions[i].outlineLevel = level_val
            ws.sheet_properties.outlinePr.summaryBelow = True
            ws.sheet_properties.outlinePr.applyStyles = True
            ws.auto_filter.ref = ws.dimensions
            ws.freeze_panes = "A2"

        # –°–≤–æ–¥–Ω–∞—è Overview (–µ—Å–ª–∏ –Ω—É–∂–Ω–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∞)
        if overview_rows:
            overview = pd.concat(overview_rows, ignore_index=True)
            pivot = pd.pivot_table(
                overview,
                index=["Release", "–¢–∏–ø"],
                columns=["–°—Ç–∞—Ç—É—Å"],
                values="–ö–ª—é—á",
                aggfunc="count",
                fill_value=0,
                margins=True,
            )
            pivot.to_excel(xw, sheet_name="Overview")
            ws_ov: Worksheet = xw.sheets["Overview"]
            ws_ov.auto_filter.ref = ws_ov.dimensions
            ws_ov.freeze_panes = "A2"

    # –ê–≤—Ç–æ—Ñ–∏—Ç —à–∏—Ä–∏–Ω—ã –ª–∏—Å—Ç–æ–≤
    excel_autofit_smart(writer_path, width_overrides={
        "–ù–æ–¥–∞": 60,
        "–°—Å—ã–ª–∫–∞": 16,
        "–ê—Ä—Ç–µ—Ñ–∞–∫—Ç": 40,
        "–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å": 28,
        "Fix Version(s)": 28,
        "Priority": 12,
    })

    print(f"–ì–æ—Ç–æ–≤–æ ‚Üí {writer_path}")

if __name__ == "__main__":
    # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∏–∑ –∫–æ–Ω—Å–æ–ª–∏:
    # python Release.py CSHRM "Rel 2025.10"
    import sys
    if len(sys.argv) >= 2:
        pk = sys.argv[1].strip()
        if pk:
            PROJECT_KEY = pk
    if len(sys.argv) >= 3:
        VERSIONS_FILTER = [sys.argv[2].strip()]
    main()
