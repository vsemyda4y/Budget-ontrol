# -*- coding: utf-8 -*-
"""
Release Composer — выгрузка состава релизов по коду проекта JIRA
(эпики → истории/задачи → сабтаски) + связи задач (в т.ч. виртуальная иерархия по типам) → Excel c иерархией.

Переменные окружения (можно задать в коде):
- JIRA_URL               — базовый URL Jira (например, https://jira.nlmk.com)
- JIRA_BEARER_TOKEN      — Bearer-токен (можно тот же, что в Worklog_with_summary_labels.py)
- PROJECT_KEY            — ключ проекта (например, "CSHRM")
- VERSIONS_FILTER        — имена версий через запятую (FixVersion). Пусто → все подходящие.
- ONLY_UNRELEASED        — "1" → только unreleased версии; "0" → все (по умолчанию "1")
- MAX_ISSUES             — защитный лимит задач на одну версию (по умолчанию 5000)
- ENABLE_LINK_HIERARCHY  — "1" → строить виртуальную иерархию по линкам (см. LINK_HIERARCHY_RULES), по умолчанию "1"
- CONFLUENCE_HOST        — подстрока хоста Confluence для поиска артефакта в remotelink (по умолчанию "confluence")
- RELEASE_NOTE_FIELD_ID  — (опц.) явный id кастомного поля для Release Note (например, customfield_12345)
- SERVICE_FIELD_ID       — (опц.) явный id кастомного поля для Service/Услуга
- COLLAPSE_LEVEL         — уровень, выше которого строки будут скрыты при открытии (по умолчанию 1 → скрывать Level>=2)

Выходной Excel:
- Только листы <Release>_Tree — иерархия для каждой версии, с легендой, цветовой подсветкой блоков/уровней, «ёлочкой».
- Overview — сводная по количеству задач по типам (без статусов).

Колонки на листах ..._Tree (итоговый порядок):
Level, Блок, Краткое содержание, Задача, Тип, Статус, Услуга, Артефакт, Release Note, Исполнитель, Fix Versions
"""

import os
import re
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import pandas as pd
import requests
from openpyxl import load_workbook
from openpyxl.styles import Alignment, PatternFill, Font
from openpyxl.utils import get_column_letter
from openpyxl.worksheet.worksheet import Worksheet

# ========= ENV =========

def _env(key: str, default: Optional[str] = None) -> str:
    """Безопасное чтение переменных окружения с защитой от пустых/None/дефисов."""
    val = os.getenv(key)
    if val is None:
        return default or ""
    val = str(val).strip()
    if val.lower() in {"none", "null", "", "-", "—", "–"}:
        return default or ""
    return val

JIRA_URL               = _env("JIRA_URL", "https://jira.nlmk.com").rstrip("/")
JIRA_BEARER_TOKEN      = _env("JIRA_BEARER_TOKEN", _env("JIRA_TEMPO_TOKEN", ""))
PROJECT_KEY            = _env("PROJECT_KEY", "CSHRM")
VERSIONS_FILTER        = [v.strip() for v in _env("VERSIONS_FILTER", "").split(",") if v.strip()]
ONLY_UNRELEASED        = _env("ONLY_UNRELEASED", "1") == "1"
MAX_ISSUES             = int(_env("MAX_ISSUES", "5000"))
ENABLE_LINK_HIERARCHY  = _env("ENABLE_LINK_HIERARCHY", "1") == "1"
CONFLUENCE_HOST        = _env("CONFLUENCE_HOST", "confluence")
RELEASE_NOTE_FIELD_ID  = _env("RELEASE_NOTE_FIELD_ID", "")
SERVICE_FIELD_ID       = _env("SERVICE_FIELD_ID", "")
COLLAPSE_LEVEL         = int(_env("COLLAPSE_LEVEL", "1"))

if not PROJECT_KEY:
    raise SystemExit("PROJECT_KEY не задан. Укажи ключ проекта, например PROJECT_KEY=CSHRM")
if not JIRA_BEARER_TOKEN:
    raise SystemExit("ENV JIRA_BEARER_TOKEN/JIRA_TEMPO_TOKEN не задан — нужен Bearer токен Jira.")

HEADERS = {
    "Authorization": f"Bearer {JIRA_BEARER_TOKEN}",
    "Accept": "application/json",
    "Content-Type": "application/json",
}

# ========= ПАПКИ ВЫХОДА =========
OUT_DIR = Path.cwd() / "release_export"
OUT_DIR.mkdir(parents=True, exist_ok=True)

# ========= Утилиты Excel =========

def make_sheet_name(base: str, suffix: str) -> str:
    """Имя листа ≤31 символ и без недопустимых знаков."""
    safe = re.sub(r'[:\\/?*\[\]]', '_', str(base or 'Release'))
    max_base = 31 - (len(suffix) + 1)
    if max_base < 1:
        max_base = 1
    safe = safe[:max_base]
    return f"{safe}_{suffix}"

def _visible_text(val: object) -> str:
    if val is None:
        return ""
    s = str(val)
    if not s.startswith("="):
        return s
    m = re.match(r'^\s*=\s*HYPERLINK\s*\(\s*"[^"]*"\s*[,;]\s*"([^"]*)"\s*\)\s*$', s, re.IGNORECASE)
    return m.group(1) if m else s

def excel_autofit_smart(path: Path, width_overrides: Optional[Dict[str,int]] = None,
                        clamp_min: int = 6, clamp_max: int = 60):
    """Автофит по всему файлу; корректно ищет строку заголовков (учитывает легенду)."""
    try:
        wb = load_workbook(path)
        for ws in wb.worksheets:
            # найти строку заголовка
            header_row_idx = 1
            for r in range(1, min(6, ws.max_row + 1)):
                vals = [str(c.value).strip() if c.value else "" for c in ws[r]]
                if "Level" in vals or "Release" in vals:
                    header_row_idx = r
                    break
            # собрать заголовки
            headers = {cell.column: (cell.value or "") for cell in ws[header_row_idx]}
            # пройтись по колонкам
            for col_cells in ws.iter_cols(min_col=1, max_col=ws.max_column,
                                          min_row=header_row_idx, max_row=ws.max_row):
                col_idx = col_cells[0].column
                head = str(headers.get(col_idx, "")).strip()
                if width_overrides and head in width_overrides:
                    ws.column_dimensions[get_column_letter(col_idx)].width = width_overrides[head]
                    continue
                max_len = max(len(_visible_text(c.value)) if c.value is not None else 0 for c in col_cells)
                max_len = max(max_len, len(head))
                ws.column_dimensions[get_column_letter(col_idx)].width = max(clamp_min, min(max_len + 2, clamp_max))
        wb.save(path)
    except Exception as e:
        print(f"[autofit] пропущено: {e}")

def hyperlink_formula(key: str) -> str:
    if not key:
        return ""
    k = str(key).strip().replace('"', '""')
    return f'=HYPERLINK("{JIRA_URL}/browse/{k}","{k}")'

def apply_wrap(ws: Worksheet, headers_to_wrap: List[str], header_row_idx: int):
    """Перенос строк и выравнивание по верхнему краю для заданных колонок."""
    header_to_col: Dict[str, int] = {}
    for cell in ws[header_row_idx]:
        if cell.value:
            header_to_col[str(cell.value).strip()] = cell.column
    for h in headers_to_wrap:
        col = header_to_col.get(h)
        if not col:
            continue
        for row in ws.iter_rows(min_row=header_row_idx, max_row=ws.max_row, min_col=col, max_col=col):
            cell = row[0]
            cell.alignment = Alignment(wrap_text=True, vertical="top")

def align_top_all(ws: Worksheet, header_row_idx: int):
    """Выравнивание по верхнему краю для всех колонок (заголовки и данные), без изменения wrap_text."""
    for row in ws.iter_rows(min_row=header_row_idx, max_row=ws.max_row, min_col=1, max_col=ws.max_column):
        for cell in row:
            cell.alignment = Alignment(
                wrap_text=cell.alignment.wrap_text,
                horizontal=cell.alignment.horizontal,
                vertical="top"
            )

def apply_row_styles(ws: Worksheet, header_row_idx: int):
    """Подсветка строк: блоки + специальный цвет для Level=1 и Level=2; жирный шрифт для Level=0."""
    headers = {str(c.value).strip(): c.column for c in ws[header_row_idx] if c.value}
    col_level = headers.get("Level")
    col_block = headers.get("Блок")
    if not col_level:
        return
    fill_dev  = PatternFill(fill_type="solid", fgColor="E6F2FF")  # Развитие — голубой
    fill_sup  = PatternFill(fill_type="solid", fgColor="FFF2CC")  # Сопровождение — жёлтый
    fill_lvl1 = PatternFill(fill_type="solid", fgColor="E8F5E9")  # Level 1 — светло-зелёный
    fill_lvl2 = PatternFill(fill_type="solid", fgColor="FFE0B2")  # Level 2 — светло-оранжевый

    for i in range(header_row_idx + 1, ws.max_row + 1):
        # level
        try:
            level_val = ws.cell(row=i, column=col_level).value
            level = int(level_val or 0)
        except Exception:
            level = 0

        # bold для верхнего уровня
        if level == 0:
            for j in range(1, ws.max_column + 1):
                ws.cell(row=i, column=j).font = Font(bold=True)

        # базовая заливка по блоку
        row_fill = None
        if col_block:
            block = str(ws.cell(row=i, column=col_block).value or "").strip().lower()
            row_fill = fill_dev if block == "развитие" else fill_sup if block == "сопровождение" else None

        # приоритетные заливки по уровню
        if level == 1:
            row_fill = fill_lvl1
        elif level == 2:
            row_fill = fill_lvl2

        if row_fill:
            for j in range(1, ws.max_column + 1):
                ws.cell(row=i, column=j).fill = row_fill

def insert_legend(ws: Worksheet, text: str):
    """Вставить строку-легенду (A1:...1), с серой заливкой и жирным шрифтом."""
    ws.insert_rows(1)
    last_col_letter = get_column_letter(ws.max_column)
    ws.merge_cells(f"A1:{last_col_letter}1")
    c = ws["A1"]
    c.value = text
    c.alignment = Alignment(horizontal="left", vertical="center", wrap_text=True)
    c.font = Font(bold=True)
    c.fill = PatternFill(fill_type="solid", fgColor="DDDDDD")

# ========= Jira helpers =========

SESSION = requests.Session()
SESSION.headers.update(HEADERS)

def jira_get(url: str, params: Optional[dict] = None) -> dict:
    r = SESSION.get(url, params=params, timeout=60)
    if r.status_code != 200:
        raise RuntimeError(f"GET {url} → {r.status_code}: {r.text[:500]}")
    return r.json()

def jira_post(url: str, payload: dict) -> dict:
    r = SESSION.post(url, json=payload, timeout=120)
    if r.status_code != 200:
        raise RuntimeError(f"POST {url} → {r.status_code}: {r.text[:500]}")
    return r.json()

def get_field_ids() -> Dict[str, str]:
    """Возвращает id кастом-полей для Epic Link, Story Points, Release Note и Service/Услуга (если есть)."""
    fields = jira_get(f"{JIRA_URL}/rest/api/2/field")
    epic_link_id = None
    story_points_id = None
    release_note_id = RELEASE_NOTE_FIELD_ID or None  # явный приоритет
    service_id = SERVICE_FIELD_ID or None           # явный приоритет
    rn_synonyms = {"release note", "release notes", "релизные заметки", "релиз нота", "релиз-нота"}
    service_synonyms = {"service", "услуга"}
    for f in fields:
        name = (f.get("name") or "").strip().lower()
        fid = f.get("id")
        if name == "epic link":
            epic_link_id = fid
        if name == "story points":
            story_points_id = fid
        if not release_note_id and name in rn_synonyms:
            release_note_id = fid
        if not service_id and name in service_synonyms:
            service_id = fid
    return {"epic_link": epic_link_id, "story_points": story_points_id,
            "release_note": release_note_id, "service": service_id}

def list_versions(project_key: str) -> List[dict]:
    if not project_key or str(project_key).strip().lower() in {"none", "null", "-", "—", "–"}:
        raise SystemExit("list_versions: пустой PROJECT_KEY — задай PROJECT_KEY=CSHRM (или свой)")
    versions = jira_get(f"{JIRA_URL}/rest/api/2/project/{project_key}/versions")
    out = []
    for v in versions:
        if VERSIONS_FILTER and v.get("name") not in VERSIONS_FILTER:
            continue
        if ONLY_UNRELEASED and v.get("released"):
            continue
        if v.get("archived"):
            continue
        out.append({
            "id": v.get("id"),
            "name": v.get("name"),
            "released": v.get("released"),
            "releaseDate": v.get("releaseDate"),
            "overdue": v.get("overdue"),
        })
    out.sort(key=lambda x: (x.get("releaseDate") is None,
                            x.get("releaseDate") or "9999-12-31",
                            str(x.get("name") or "")))
    if not out:
        print("[warn] Версии не найдены по заданным фильтрам. Попробуй снять ONLY_UNRELEASED или задать VERSIONS_FILTER.")
    return out

def jql_search(jql: str, fields: List[str], max_results: int = 1000) -> List[dict]:
    url = f"{JIRA_URL}/rest/api/2/search"
    start_at = 0
    issues: List[dict] = []
    while True:
        payload = {
            "jql": jql,
            "startAt": start_at,
            "maxResults": min(100, max_results - start_at),
            "fields": fields,
        }
        data = jira_post(url, payload)
        issues.extend(data.get("issues", []))
        fetched = len(data.get("issues", []))
        start_at += fetched
        if start_at >= data.get("total", 0) or start_at >= max_results or fetched == 0:
            break
    return issues

def get_confluence_artifact(issue_key: str) -> str:
    """Возвращает формулу Excel HYPERLINK на первую Confluence-ссылку из remotelink задачи.
    Если не найдено — пустая строка.
    """
    try:
        arr = jira_get(f"{JIRA_URL}/rest/api/2/issue/{issue_key}/remotelink")
    except Exception:
        return ""
    host = CONFLUENCE_HOST.lower().strip()
    for rl in arr or []:
        obj = (rl or {}).get("object") or {}
        url = (obj.get("url") or "").strip()
        title = (obj.get("title") or "Confluence").strip()
        if url and (host in url.lower()):
            u = url.replace('"', '""')
            t = title.replace('"', '""')
            return f'=HYPERLINK("{u}","{t}")'
    return ""

# ========= Иерархия по линкам =========
LINK_HIERARCHY_RULES = [
    ("engineering concept", "change request"),
    ("support", "bugfix"),
]

def _block_by_type(issue_type: str) -> str:
    t = (issue_type or "").strip().lower()
    if t in {"engineering concept", "change request"}:
        return "Развитие"
    if t in {"support", "bugfix"}:
        return "Сопровождение"
    return ""

# ========= Построение иерархии =========

EPIC_LINK_FIELD_ID: Optional[str] = None
STORY_POINTS_FIELD_ID: Optional[str] = None
RELEASE_NOTE_FIELD_ID_RESOLVED: Optional[str] = None
SERVICE_FIELD_ID_RESOLVED: Optional[str] = None

def flatten_release_tree(release_name: str, issues: List[dict], epic_link_field: Optional[str]) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """Строит иерархию и таблицу связей для заданного релиза."""
    by_key = {i.get("key"): i for i in issues}

    def _g(obj, path: List[str]):
        for p in path:
            if obj is None:
                return None
            obj = obj.get(p) if isinstance(obj, dict) else None
        return obj

    # индексы
    children: Dict[str, List[str]] = {}
    epic_children: Dict[str, List[str]] = {}
    parent_map: Dict[str, Optional[str]] = {}
    epic_of: Dict[str, Optional[str]] = {}

    # связи
    links_rows: List[dict] = []
    link_pairs: List[Tuple[str, str]] = []

    def issue_type_name(i: dict) -> str:
        return _g(i.get("fields", {}), ["issuetype", "name"]) or ""

    for k, it in by_key.items():
        fields = it.get("fields", {})
        parent = _g(fields, ["parent", "key"]) or None
        parent_map[k] = parent
        if parent:
            children.setdefault(parent, []).append(k)
        epic = fields.get(epic_link_field) if epic_link_field else None
        if isinstance(epic, dict):
            epic = epic.get("key")
        epic_of[k] = epic
        if epic:
            epic_children.setdefault(epic, []).append(k)
        for l in fields.get("issuelinks") or []:
            ltype = _g(l, ["type", "name"]) or ""
            inward = _g(l, ["inwardIssue", "key"]) or None
            outward = _g(l, ["outwardIssue", "key"]) or None
            if inward:
                links_rows.append({"From": k, "Direction": "inward", "Type": ltype, "To": inward})
                link_pairs.append((k, inward))
            if outward:
                links_rows.append({"From": k, "Direction": "outward", "Type": ltype, "To": outward})
                link_pairs.append((k, outward))

    _artifact_cache: Dict[str, str] = {}
    def artifact_for(key: str) -> str:
        if key not in _artifact_cache:
            _artifact_cache[key] = get_confluence_artifact(key)
        return _artifact_cache[key]

    # виртуальная иерархия
    if ENABLE_LINK_HIERARCHY and LINK_HIERARCHY_RULES:
        rules = [(a.lower(), b.lower()) for a, b in LINK_HIERARCHY_RULES]
        for a, b in link_pairs:
            ia = by_key.get(a); ib = by_key.get(b)
            if not ia or not ib:
                continue
            ta = issue_type_name(ia).lower(); tb = issue_type_name(ib).lower()
            if (ta, tb) in rules and not parent_map.get(b) and not epic_of.get(b):
                parent_map[b] = a
                children.setdefault(a, []).append(b)
            if (tb, ta) in rules and not parent_map.get(a) and not epic_of.get(a):
                parent_map[a] = b
                children.setdefault(b, []).append(a)

    def _tree_prefix(prefix_last_flags: List[bool], is_last: Optional[bool]) -> str:
        if not prefix_last_flags and is_last is None:
            return ""
        parts: List[str] = []
        for last in prefix_last_flags:
            parts.append("   " if last else "│  ")
        if is_last is not None:
            parts.append("└─ " if is_last else "├─ ")
        return "".join(parts)

    epics = [k for k, it in by_key.items() if issue_type_name(it).lower() == "epic"]
    roots_wo_epic = [k for k, it in by_key.items() if (k not in epics and not parent_map.get(k) and not epic_of.get(k))]

    def _extract_field_value(raw):
        if isinstance(raw, dict):
            return str(raw.get("value") or raw.get("name") or raw.get("displayName") or "")
        if isinstance(raw, list):
            return ", ".join(str(x.get("value") if isinstance(x, dict) else x) for x in raw if x not in (None, ""))
        return "" if raw is None else str(raw)

    def row_from_key(key: str, level: int, rel_name: str, prefix: str) -> dict:
        it = by_key[key]
        f = it.get("fields", {})
        assignee = _g(f, ["assignee", "displayName"]) or ""
        status = _g(f, ["status", "name"]) or ""
        issue_type = _g(f, ["issuetype", "name"]) or ""
        summary = f.get("summary") or ""
        release_note = _extract_field_value(f.get(RELEASE_NOTE_FIELD_ID_RESOLVED)) if RELEASE_NOTE_FIELD_ID_RESOLVED else ""
        service_val  = _extract_field_value(f.get(SERVICE_FIELD_ID_RESOLVED)) if SERVICE_FIELD_ID_RESOLVED else ""
        fix_versions = ", ".join((v.get("name") for v in (f.get("fixVersions") or [])))
        block = _block_by_type(issue_type)
        return {
            "Release": rel_name,
            "Level": level,
            "Блок": block,
            "Краткое содержание": prefix + summary,
            "Задача": hyperlink_formula(key),
            "Тип": issue_type,
            "Статус": status,
            "Услуга": service_val,
            "Артефакт": artifact_for(key),
            "Release Note": release_note,
            "Исполнитель": assignee,
            "Fix Versions": fix_versions,
        }

    rows: List[dict] = []

    def _sorted_kids(parent_key: str) -> List[str]:
        return sorted(children.get(parent_key, []))

    def walk_issue(key: str, level: int, prefix_flags: List[bool], is_last: Optional[bool]):
        prefix = _tree_prefix(prefix_flags, is_last)
        rows.append(row_from_key(key, level, release_name, prefix))
        kids = _sorted_kids(key)
        for idx, ch in enumerate(kids):
            last = (idx == len(kids) - 1)
            walk_issue(ch, level + 1, prefix_flags + [is_last if is_last is not None else True], last)

    for e in sorted(epics):
        rows.append(row_from_key(e, 0, release_name, prefix=""))
        first_level = sorted(set(children.get(e, []) + epic_children.get(e, [])))
        for idx, k in enumerate(first_level):
            last = (idx == len(first_level) - 1)
            walk_issue(k, 1, [], last)

    if roots_wo_epic:
        rows.append({
            "Release": release_name,
            "Level": 0,
            "Блок": "",
            "Краткое содержание": "(без эпика)",
            "Задача": "",
            "Тип": "",
            "Статус": "",
            "Услуга": "",
            "Артефакт": "",
            "Release Note": "",
            "Исполнитель": "",
            "Fix Versions": "",
        })
        for idx, k in enumerate(sorted(roots_wo_epic)):
            last = (idx == len(roots_wo_epic) - 1)
            walk_issue(k, 1, [], last)

    tree_df = pd.DataFrame(rows)
    links_df = pd.DataFrame(links_rows) if links_rows else pd.DataFrame(columns=["From","Direction","Type","To"])
    return tree_df, links_df

# ========= Основной сценарий =========

def main():
    global EPIC_LINK_FIELD_ID, STORY_POINTS_FIELD_ID, RELEASE_NOTE_FIELD_ID_RESOLVED, SERVICE_FIELD_ID_RESOLVED

    print("=== Release Composer: старт ===")
    print(f"JIRA_URL               : {JIRA_URL}")
    print(f"PROJECT_KEY            : {PROJECT_KEY}")
    print(f"ONLY_UNRELEASED        : {ONLY_UNRELEASED}")
    print(f"VERSIONS_FILTER        : {', '.join(VERSIONS_FILTER) if VERSIONS_FILTER else '(все подходящие)'}")
    print(f"ENABLE_LINK_HIERARCHY  : {ENABLE_LINK_HIERARCHY}")
    print(f"CONFLUENCE_HOST        : {CONFLUENCE_HOST}")

    versions = list_versions(PROJECT_KEY)
    if not versions:
        raise SystemExit("Нет подходящих версий (проверь фильтры/права)")

    ids = get_field_ids()
    EPIC_LINK_FIELD_ID = ids.get("epic_link")
    STORY_POINTS_FIELD_ID = ids.get("story_points")
    RELEASE_NOTE_FIELD_ID_RESOLVED = ids.get("release_note")
    SERVICE_FIELD_ID_RESOLVED = ids.get("service")
    if not EPIC_LINK_FIELD_ID:
        print("[warn] Не нашёл id 'Epic Link' — иерархия может быть неполной")
    if RELEASE_NOTE_FIELD_ID:
        RELEASE_NOTE_FIELD_ID_RESOLVED = RELEASE_NOTE_FIELD_ID
    if SERVICE_FIELD_ID:
        SERVICE_FIELD_ID_RESOLVED = SERVICE_FIELD_ID

    fields = [
        "summary", "issuetype", "status", "assignee", "parent",
        "subtasks", "issuelinks", "priority", "fixVersions"
    ]
    if EPIC_LINK_FIELD_ID:
        fields.append(EPIC_LINK_FIELD_ID)
    if RELEASE_NOTE_FIELD_ID_RESOLVED:
        fields.append(RELEASE_NOTE_FIELD_ID_RESOLVED)
    if SERVICE_FIELD_ID_RESOLVED:
        fields.append(SERVICE_FIELD_ID_RESOLVED)

    per_release = []
    overview_rows: List[pd.DataFrame] = []

    for v in versions:
        vname = v.get("name")
        print(f"→ Версия: {vname}")
        jql = f'project={PROJECT_KEY} AND fixVersion="{vname}" ORDER BY issuetype, key'
        issues = jql_search(jql, fields, max_results=MAX_ISSUES)
        if not issues:
            print("  (нет задач)")
            continue

        tmp = []
        for it in issues:
            f = it.get("fields", {})
            tmp.append({
                "Release": vname,
                "Тип": (f.get("issuetype") or {}).get("name"),
                "Ключ": it.get("key"),
            })
        ov = pd.DataFrame(tmp)
        overview_rows.append(ov)

        tree_df, links_df = flatten_release_tree(vname, issues, EPIC_LINK_FIELD_ID)

        # Порядок колонок
        tree_cols = [
            "Level", "Блок", "Краткое содержание", "Задача", "Тип", "Статус",
            "Услуга", "Артефакт", "Release Note", "Исполнитель", "Fix Versions"
        ]
        tree_df = tree_df[tree_cols]

        # Порядок блоков: Развитие → Сопровождение → прочее
        block_order_map = {"Развитие": 0, "Сопровождение": 1}
        tree_df["_block_order"] = tree_df["Блок"].map(block_order_map).fillna(2)
        tree_df = tree_df.sort_values(by=["_block_order"], kind="stable").drop(columns=["_block_order"])

        per_release.append((vname, tree_df, links_df, ov))

    if not per_release:
        raise SystemExit("Нет задач ни в одной из подходящих версий")

    writer_path = OUT_DIR / f"release_composer_{PROJECT_KEY}_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.xlsx"
    with pd.ExcelWriter(writer_path, engine="openpyxl") as xw:
        for vname, tree_df, links_df, _ov in per_release:
            sheet_tree = make_sheet_name(vname, "Tree")
            tree_df.to_excel(xw, index=False, sheet_name=sheet_tree)
            ws: Worksheet = xw.sheets[sheet_tree]

            insert_legend(ws, "Блоки: Развитие — голубой; Сопровождение — жёлтый; Level 1 — светло-зелёный; Level 2 — светло-оранжевый")

            last_col_letter = get_column_letter(ws.max_column)
            ws.auto_filter.ref = f"A2:{last_col_letter}{ws.max_row}"
            ws.freeze_panes = "A3"

            for df_idx in range(len(tree_df)):
                excel_row = 3 + df_idx
                try:
                    level_val = int(tree_df.iloc[df_idx]["Level"] or 0)
                except Exception:
                    level_val = 0
                ws.row_dimensions[excel_row].outlineLevel = level_val
                if level_val > COLLAPSE_LEVEL:
                    ws.row_dimensions[excel_row].hidden = True

            ws.sheet_properties.outlinePr.summaryBelow = True
            ws.sheet_properties.outlinePr.applyStyles = True

            apply_wrap(ws, ["Краткое содержание", "Release Note"], header_row_idx=2)
            align_top_all(ws, header_row_idx=2)
            apply_row_styles(ws, header_row_idx=2)

        # ===== Overview: количество задач по типам (без статусов) =====
        if overview_rows:
            overview = pd.concat(overview_rows, ignore_index=True)
            pivot = pd.pivot_table(
                overview,
                index=["Release"],
                columns=["Тип"],
                values="Ключ",
                aggfunc="count",
                fill_value=0,
                margins=True,
            )
            pivot.to_excel(xw, sheet_name="Overview")
            ws_ov: Worksheet = xw.sheets["Overview"]
            ws_ov.auto_filter.ref = ws_ov.dimensions
            ws_ov.freeze_panes = "A2"
            # выравнивание по верхнему краю в Overview
            for row in ws_ov.iter_rows(min_row=1, max_row=ws_ov.max_row, min_col=1, max_col=ws_ov.max_column):
                for cell in row:
                    cell.alignment = Alignment(
                        wrap_text=cell.alignment.wrap_text,
                        horizontal=cell.alignment.horizontal,
                        vertical="top"
                    )

    # Автофит ширины листов (включая Overview)
    excel_autofit_smart(writer_path, width_overrides={
        "Level": 6,
        "Блок": 16,
        "Краткое содержание": 60,
        "Задача": 16,
        "Тип": 18,
        "Статус": 16,
        "Услуга": 20,
        # "Артефакт": auto,
        "Release Note": 50,
        # "Исполнитель": auto,
        "Fix Versions": 28,
    })

    print(f"Готово → {writer_path}")

if __name__ == "__main__":
    import sys
    if len(sys.argv) >= 2:
        pk = sys.argv[1].strip()
        if pk:
            PROJECT_KEY = pk
    if len(sys.argv) >= 3:
        VERSIONS_FILTER = [sys.argv[2].strip()]
    main()
