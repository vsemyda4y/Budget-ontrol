# -*- coding: utf-8 -*-
"""
Release Composer — выгрузка состава релизов по коду проекта JIRA
(эпики → истории/задачи → сабтаски) + связи задач (в т.ч. виртуальная иерархия по типам) → Excel c иерархией.

Переменные окружения (можно задать в коде):
- JIRA_URL               — базовый URL Jira (например, https://jira.nlmk.com)
- JIRA_BEARER_TOKEN      — Bearer-токен (можно тот же, что в Worklog_with_summary_labels.py)
- PROJECT_KEY            — ключ проекта (например, "CSHRM")
- VERSIONS_FILTER        — имена версий через запятую (FixVersion). Пусто → все подходящие.
- ONLY_UNRELEASED        — "1" → только unreleased версии; "0" → все (по умолчанию "1")
- MAX_ISSUES             — защитный лимит задач на одну версию (по умолчанию 5000)
- ENABLE_LINK_HIERARCHY  — "1" → строить виртуальную иерархию по линкам (см. LINK_HIERARCHY_RULES), по умолчанию "1"
- CONFLUENCE_HOST        — подстрока хоста Confluence для поиска артефакта в remotelink (по умолчанию "confluence")
- RELEASE_NOTE_FIELD_ID  — (опц.) явный id кастомного поля для Release Note (например, customfield_12345)
- SERVICE_FIELD_ID       — (опц.) явный id кастомного поля для Service/Услуга
- COLLAPSE_LEVEL         — уровень, выше которого строки будут скрыты при открытии (по умолчанию 1 → скрывать Level>=2)

Выходной Excel:
- Только листы <Release>_Tree — иерархия для каждой версии, с легендой и цветовой подсветкой блоков.
- Overview — сводная по типам/статусам (оставлено; скажешь — уберу).

Колонки на листах ..._Tree:
Level, Блок, Услуга, Краткое содержание, Задача, Артефакт, Release Note, Тип, Статус, Исполнитель, Story Points, Priority, Fix Version(s), Created, Updated
"""

import os
import re
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import pandas as pd
import requests
from openpyxl import load_workbook
from openpyxl.styles import Alignment, PatternFill, Font
from openpyxl.utils import get_column_letter
from openpyxl.worksheet.worksheet import Worksheet

# ========= ENV =========

def _env(key: str, default: Optional[str] = None) -> str:
    """Безопасное чтение переменных окружения с защитой от пустых/None/дефисов."""
    val = os.getenv(key)
    if val is None:
        return default or ""
    val = str(val).strip()
    if val.lower() in {"none", "null", "", "-", "—", "–"}:
        return default or ""
    return val

JIRA_URL               = _env("JIRA_URL", "https://jira.nlmk.com").rstrip("/")
JIRA_BEARER_TOKEN      = _env("JIRA_BEARER_TOKEN", _env("JIRA_TEMPO_TOKEN", ""))
PROJECT_KEY            = _env("PROJECT_KEY", "CSHRM")
VERSIONS_FILTER        = [v.strip() for v in _env("VERSIONS_FILTER", "").split(",") if v.strip()]
ONLY_UNRELEASED        = _env("ONLY_UNRELEASED", "1") == "1"
MAX_ISSUES             = int(_env("MAX_ISSUES", "5000"))
ENABLE_LINK_HIERARCHY  = _env("ENABLE_LINK_HIERARCHY", "1") == "1"
CONFLUENCE_HOST        = _env("CONFLUENCE_HOST", "confluence")
RELEASE_NOTE_FIELD_ID  = _env("RELEASE_NOTE_FIELD_ID", "")
SERVICE_FIELD_ID       = _env("SERVICE_FIELD_ID", "")
COLLAPSE_LEVEL         = int(_env("COLLAPSE_LEVEL", "1"))

if not PROJECT_KEY:
    raise SystemExit("PROJECT_KEY не задан. Укажи ключ проекта, например PROJECT_KEY=CSHRM")
if not JIRA_BEARER_TOKEN:
    raise SystemExit("ENV JIRA_BEARER_TOKEN/JIRA_TEMPO_TOKEN не задан — нужен Bearer токен Jira.")

HEADERS = {
    "Authorization": f"Bearer {JIRA_BEARER_TOKEN}",
    "Accept": "application/json",
    "Content-Type": "application/json",
}

# ========= ПАПКИ ВЫХОДА =========
OUT_DIR = Path.cwd() / "release_export"
OUT_DIR.mkdir(parents=True, exist_ok=True)

# ========= Утилиты Excel =========

def make_sheet_name(base: str, suffix: str) -> str:
    """Имя листа ≤31 символ и без недопустимых знаков."""
    safe = re.sub(r'[:\\/?*\[\]]', '_', str(base or 'Release'))
    max_base = 31 - (len(suffix) + 1)  # +1 под "_"
    if max_base < 1:
        max_base = 1
    safe = safe[:max_base]
    return f"{safe}_{suffix}"

def _visible_text(val: object) -> str:
    if val is None:
        return ""
    s = str(val)
    if not s.startswith("="):
        return s
    m = re.match(r'^\s*=\s*HYPERLINK\s*\(\s*"[^"]*"\s*[,;]\s*"([^"]*)"\s*\)\s*$', s, re.IGNORECASE)
    return m.group(1) if m else s

def excel_autofit_smart(path: Path, width_overrides: Optional[Dict[str,int]] = None,
                        clamp_min: int = 6, clamp_max: int = 60):
    """Автофит с поддержкой «легенды» на первой строке: ищем строку заголовков (там где есть 'Level')."""
    try:
        wb = load_workbook(path)
        for ws in wb.worksheets:
            # найти строку заголовка
            header_row_idx = 1
            for r in range(1, min(6, ws.max_row + 1)):
                vals = [str(c.value).strip() if c.value else "" for c in ws[r]]
                if "Level" in vals:
                    header_row_idx = r
                    break
            # собрать заголовки
            headers = {cell.column: (cell.value or "") for cell in ws[header_row_idx]}
            # пройтись по колонкам, начиная с header_row_idx
            for col_cells in ws.iter_cols(min_col=1, max_col=ws.max_column,
                                          min_row=header_row_idx, max_row=ws.max_row):
                col_idx = col_cells[0].column
                head = str(headers.get(col_idx, "")).strip()
                if width_overrides and head in width_overrides:
                    ws.column_dimensions[get_column_letter(col_idx)].width = width_overrides[head]
                    continue
                max_len = max(len(_visible_text(c.value)) if c.value is not None else 0 for c in col_cells)
                max_len = max(max_len, len(head))
                ws.column_dimensions[get_column_letter(col_idx)].width = max(clamp_min, min(max_len + 2, clamp_max))
        wb.save(path)
    except Exception as e:
        print(f"[autofit] пропущено: {e}")

def hyperlink_formula(key: str) -> str:
    if not key:
        return ""
    k = str(key).strip().replace('"', '""')
    return f'=HYPERLINK("{JIRA_URL}/browse/{k}","{k}")'

def apply_wrap(ws: Worksheet, headers_to_wrap: List[str], header_row_idx: int):
    """Включить перенос строк и выравнивание по верхнему краю для заданных колонок по имени заголовка."""
    header_to_col: Dict[str, int] = {}
    for cell in ws[header_row_idx]:
        if cell.value:
            header_to_col[str(cell.value).strip()] = cell.column
    for h in headers_to_wrap:
        col = header_to_col.get(h)
        if not col:
            continue
        for row in ws.iter_rows(min_row=header_row_idx, max_row=ws.max_row, min_col=col, max_col=col):
            cell = row[0]
            cell.alignment = Alignment(wrap_text=True, vertical="top")

def align_top(ws: Worksheet, headers_to_align: List[str], header_row_idx: int):
    """Только выравнивание по верхнему краю (без переноса)."""
    header_to_col: Dict[str, int] = {}
    for cell in ws[header_row_idx]:
        if cell.value:
            header_to_col[str(cell.value).strip()] = cell.column
    for h in headers_to_align:
        col = header_to_col.get(h)
        if not col:
            continue
        for row in ws.iter_rows(min_row=header_row_idx, max_row=ws.max_row, min_col=col, max_col=col):
            cell = row[0]
            cell.alignment = Alignment(vertical="top")

def apply_row_styles(ws: Worksheet, header_row_idx: int):
    """Подсветка строк по блоку и жирный шрифт для верхнего уровня."""
    headers = {str(c.value).strip(): c.column for c in ws[header_row_idx] if c.value}
    col_level = headers.get("Level")
    col_block = headers.get("Блок")
    if not col_level:
        return
    fill_dev = PatternFill(fill_type="solid", fgColor="E6F2FF")  # Развитие — голубой
    fill_sup = PatternFill(fill_type="solid", fgColor="FFF2CC")  # Сопровождение — жёлтый
    # обойти строки данных
    for i in range(header_row_idx + 1, ws.max_row + 1):
        # level
        try:
            level_val = ws.cell(row=i, column=col_level).value
            level = int(level_val or 0)
        except Exception:
            level = 0
        # bold для верхнего уровня
        if level == 0:
            for j in range(1, ws.max_column + 1):
                ws.cell(row=i, column=j).font = Font(bold=True)
        # заливка по блоку
        if col_block:
            block = str(ws.cell(row=i, column=col_block).value or "").strip().lower()
            fill = fill_dev if block == "развитие" else fill_sup if block == "сопровождение" else None
            if fill:
                for j in range(1, ws.max_column + 1):
                    ws.cell(row=i, column=j).fill = fill

def insert_legend(ws: Worksheet, text: str):
    """Вставить строку-легенду (A1:...1), с серой заливкой и жирным шрифтом."""
    ws.insert_rows(1)
    last_col_letter = get_column_letter(ws.max_column)
    ws.merge_cells(f"A1:{last_col_letter}1")
    c = ws["A1"]
    c.value = text
    c.alignment = Alignment(horizontal="left", vertical="center", wrap_text=True)
    c.font = Font(bold=True)
    c.fill = PatternFill(fill_type="solid", fgColor="DDDDDD")

# ========= Jira helpers =========

SESSION = requests.Session()
SESSION.headers.update(HEADERS)

def jira_get(url: str, params: Optional[dict] = None) -> dict:
    r = SESSION.get(url, params=params, timeout=60)
    if r.status_code != 200:
        raise RuntimeError(f"GET {url} → {r.status_code}: {r.text[:500]}")
    return r.json()

def jira_post(url: str, payload: dict) -> dict:
    r = SESSION.post(url, json=payload, timeout=120)
    if r.status_code != 200:
        raise RuntimeError(f"POST {url} → {r.status_code}: {r.text[:500]}")
    return r.json()

def get_field_ids() -> Dict[str, str]:
    """Возвращает id кастом-полей для Epic Link, Story Points, Release Note и Service/Услуга (если есть)."""
    fields = jira_get(f"{JIRA_URL}/rest/api/2/field")
    epic_link_id = None
    story_points_id = None
    release_note_id = RELEASE_NOTE_FIELD_ID or None  # явный приоритет
    service_id = SERVICE_FIELD_ID or None           # явный приоритет
    rn_synonyms = {"release note", "release notes", "релизные заметки", "релиз нота", "релиз-нота"}
    service_synonyms = {"service", "услуга"}
    for f in fields:
        name = (f.get("name") or "").strip().lower()
        fid = f.get("id")
        if name == "epic link":
            epic_link_id = fid
        if name == "story points":
            story_points_id = fid
        if not release_note_id and name in rn_synonyms:
            release_note_id = fid
        if not service_id and name in service_synonyms:
            service_id = fid
    return {"epic_link": epic_link_id, "story_points": story_points_id,
            "release_note": release_note_id, "service": service_id}

def list_versions(project_key: str) -> List[dict]:
    if not project_key or str(project_key).strip().lower() in {"none", "null", "-", "—", "–"}:
        raise SystemExit("list_versions: пустой PROJECT_KEY — задай PROJECT_KEY=CSHRM (или свой)")
    versions = jira_get(f"{JIRA_URL}/rest/api/2/project/{project_key}/versions")
    out = []
    for v in versions:
        if VERSIONS_FILTER and v.get("name") not in VERSIONS_FILTER:
            continue
        if ONLY_UNRELEASED and v.get("released"):
            continue
        if v.get("archived"):
            continue
        out.append({
            "id": v.get("id"),
            "name": v.get("name"),
            "released": v.get("released"),
            "releaseDate": v.get("releaseDate"),
            "overdue": v.get("overdue"),
        })
    out.sort(key=lambda x: (x.get("releaseDate") is None,
                            x.get("releaseDate") or "9999-12-31",
                            str(x.get("name") or "")))
    if not out:
        print("[warn] Версии не найдены по заданным фильтрам. Попробуй снять ONLY_UNRELEASED или задать VERSIONS_FILTER.")
    return out

def jql_search(jql: str, fields: List[str], max_results: int = 1000) -> List[dict]:
    url = f"{JIRA_URL}/rest/api/2/search"
    start_at = 0
    issues: List[dict] = []
    while True:
        payload = {
            "jql": jql,
            "startAt": start_at,
            "maxResults": min(100, max_results - start_at),
            "fields": fields,
        }
        data = jira_post(url, payload)
        issues.extend(data.get("issues", []))
        fetched = len(data.get("issues", []))
        start_at += fetched
        if start_at >= data.get("total", 0) or start_at >= max_results or fetched == 0:
            break
    return issues

def get_confluence_artifact(issue_key: str) -> str:
    """Возвращает формулу Excel HYPERLINK на первую Confluence-ссылку из remotelink задачи.
    Если не найдено — пустая строка.
    """
    try:
        arr = jira_get(f"{JIRA_URL}/rest/api/2/issue/{issue_key}/remotelink")
    except Exception:
        return ""
    host = CONFLUENCE_HOST.lower().strip()
    for rl in arr or []:
        obj = (rl or {}).get("object") or {}
        url = (obj.get("url") or "").strip()
        title = (obj.get("title") or "Confluence").strip()
        if url and (host in url.lower()):
            u = url.replace('"', '""')
            t = title.replace('"', '""')
            return f'=HYPERLINK("{u}","{t}")'
    return ""

# ========= Иерархия по линкам =========
# parent_type → child_type (case-insensitive)
LINK_HIERARCHY_RULES = [
    ("engineering concept", "change request"),
    ("support", "bugfix"),
]

def _block_by_type(issue_type: str) -> str:
    t = (issue_type or "").strip().lower()
    if t in {"engineering concept", "change request"}:
        return "Развитие"
    if t in {"support", "bugfix"}:
        return "Сопровождение"
    return ""

# ========= Построение иерархии =========

EPIC_LINK_FIELD_ID: Optional[str] = None
STORY_POINTS_FIELD_ID: Optional[str] = None
RELEASE_NOTE_FIELD_ID_RESOLVED: Optional[str] = None
SERVICE_FIELD_ID_RESOLVED: Optional[str] = None

def flatten_release_tree(release_name: str, issues: List[dict], epic_link_field: Optional[str]) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """Строит иерархию и таблицу связей для заданного релиза.
    Дополнительно: если ENABLE_LINK_HIERARCHY=1 — создаёт виртуальные связи parent→child по типам задач согласно LINK_HIERARCHY_RULES.
    """
    by_key = {i.get("key"): i for i in issues}

    def _g(obj, path: List[str]):
        for p in path:
            if obj is None:
                return None
            obj = obj.get(p) if isinstance(obj, dict) else None
        return obj

    # индексы
    children: Dict[str, List[str]] = {}
    epic_children: Dict[str, List[str]] = {}
    parent_map: Dict[str, Optional[str]] = {}
    epic_of: Dict[str, Optional[str]] = {}

    # связи
    links_rows: List[dict] = []
    link_pairs: List[Tuple[str, str]] = []

    def issue_type_name(i: dict) -> str:
        return _g(i.get("fields", {}), ["issuetype", "name"]) or ""

    for k, it in by_key.items():
        fields = it.get("fields", {})
        # parent/subtasks
        parent = _g(fields, ["parent", "key"]) or None
        parent_map[k] = parent
        if parent:
            children.setdefault(parent, []).append(k)
        # epic link
        epic = fields.get(epic_link_field) if epic_link_field else None
        if isinstance(epic, dict):
            epic = epic.get("key")
        epic_of[k] = epic
        if epic:
            epic_children.setdefault(epic, []).append(k)
        # issue links (собираем пары)
        for l in fields.get("issuelinks") or []:
            ltype = _g(l, ["type", "name"]) or ""
            inward = _g(l, ["inwardIssue", "key"]) or None
            outward = _g(l, ["outwardIssue", "key"]) or None
            if inward:
                links_rows.append({"From": k, "Direction": "inward", "Type": ltype, "To": inward})
                link_pairs.append((k, inward))
            if outward:
                links_rows.append({"From": k, "Direction": "outward", "Type": ltype, "To": outward})
                link_pairs.append((k, outward))

    # Кеш Confluence-артефактов
    _artifact_cache: Dict[str, str] = {}
    def artifact_for(key: str) -> str:
        if key not in _artifact_cache:
            _artifact_cache[key] = get_confluence_artifact(key)
        return _artifact_cache[key]

    # Виртуальная иерархия по ссылкам
    if ENABLE_LINK_HIERARCHY and LINK_HIERARCHY_RULES:
        rules = [(a.lower(), b.lower()) for a, b in LINK_HIERARCHY_RULES]
        for a, b in link_pairs:
            ia = by_key.get(a); ib = by_key.get(b)
            if not ia or not ib:
                continue
            ta = issue_type_name(ia).lower(); tb = issue_type_name(ib).lower()
            # A → B
            if (ta, tb) in rules:
                if not parent_map.get(b) and not epic_of.get(b):
                    parent_map[b] = a
                    children.setdefault(a, []).append(b)
            # B → A
            if (tb, ta) in rules:
                if not parent_map.get(a) and not epic_of.get(a):
                    parent_map[a] = b
                    children.setdefault(b, []).append(a)

    # ---------- helpers для отрисовки "елочки" ----------
    def _tree_prefix(prefix_last_flags: List[bool], is_last: Optional[bool]) -> str:
        if not prefix_last_flags and is_last is None:
            return ""
        s_parts: List[str] = []
        for last in prefix_last_flags:
            s_parts.append("   " if last else "│  ")
        if is_last is not None:
            s_parts.append("└─ " if is_last else "├─ ")
        return "".join(s_parts)

    # корневые группы
    epics = [k for k, it in by_key.items() if issue_type_name(it).lower() == "epic"]
    roots_wo_epic = [k for k, it in by_key.items() if (k not in epics and not parent_map.get(k) and not epic_of.get(k))]

    def _extract_field_value(raw):
        if isinstance(raw, dict):
            return str(raw.get("value") or raw.get("name") or raw.get("displayName") or "")
        if isinstance(raw, list):
            return ", ".join(str(x.get("value") if isinstance(x, dict) else x) for x in raw if x not in (None, ""))
        return "" if raw is None else str(raw)

    def row_from_key(key: str, level: int, rel_name: str, prefix: str) -> dict:
        it = by_key[key]
        f = it.get("fields", {})
        assignee = _g(f, ["assignee", "displayName"]) or ""
        status = _g(f, ["status", "name"]) or ""
        issue_type = issue_type_name(it)
        priority = _g(f, ["priority", "name"]) or ""
        created = _g(f, ["created"]) or ""
        updated = _g(f, ["updated"]) or ""
        summary = f.get("summary") or ""
        # Release Note
        release_note = _extract_field_value(f.get(RELEASE_NOTE_FIELD_ID_RESOLVED)) if RELEASE_NOTE_FIELD_ID_RESOLVED else ""
        # Service / Услуга
        service_val = _extract_field_value(f.get(SERVICE_FIELD_ID_RESOLVED)) if SERVICE_FIELD_ID_RESOLVED else ""
        sp_raw = f.get(STORY_POINTS_FIELD_ID) if STORY_POINTS_FIELD_ID else None
        if isinstance(sp_raw, (int, float)):
            story_points = sp_raw
        else:
            try:
                story_points = float(sp_raw) if sp_raw is not None and str(sp_raw).strip() != "" else None
            except Exception:
                story_points = None
        fix_versions = ", ".join((v.get("name") for v in (f.get("fixVersions") or [])))
        block = _block_by_type(issue_type)
        return {
            "Release": rel_name,  # тех. поле (в Excel не выводим)
            "Level": level,
            "Блок": block,
            "Услуга": service_val,
            "Краткое содержание": prefix + summary,
            "Задача": hyperlink_formula(key),
            "Артефакт": artifact_for(key),
            "Release Note": release_note,
            "Тип": issue_type,
            "Статус": status,
            "Исполнитель": assignee,
            "Story Points": story_points,
            "Priority": priority,
            "Fix Version(s)": fix_versions,
            "Created": created,
            "Updated": updated,
        }

    rows: List[dict] = []

    def _sorted_kids(parent_key: str) -> List[str]:
        return sorted(children.get(parent_key, []))

    def walk_issue(key: str, level: int, prefix_flags: List[bool], is_last: Optional[bool]):
        prefix = _tree_prefix(prefix_flags, is_last)
        rows.append(row_from_key(key, level, release_name, prefix))
        kids = _sorted_kids(key)
        for idx, ch in enumerate(kids):
            last = (idx == len(kids) - 1)
            walk_issue(ch, level + 1, prefix_flags + [is_last if is_last is not None else True], last)

    # 1) Эпики → их дети
    for e in sorted(epics):
        rows.append(row_from_key(e, 0, release_name, prefix=""))
        first_level = sorted(set(children.get(e, []) + epic_children.get(e, [])))
        for idx, k in enumerate(first_level):
            last = (idx == len(first_level) - 1)
            walk_issue(k, 1, [], last)

    # 2) Без эпика и без родителя — верхний уровень
    if roots_wo_epic:
        rows.append({
            "Release": release_name,
            "Level": 0,
            "Блок": "",
            "Услуга": "",
            "Краткое содержание": "(без эпика)",
            "Задача": "",
            "Артефакт": "",
            "Release Note": "",
            "Тип": "",
            "Статус": "",
            "Исполнитель": "",
            "Story Points": None,
            "Priority": "",
            "Fix Version(s)": "",
            "Created": "",
            "Updated": "",
        })
        for idx, k in enumerate(sorted(roots_wo_epic)):
            last = (idx == len(roots_wo_epic) - 1)
            walk_issue(k, 1, [], last)

    tree_df = pd.DataFrame(rows)
    links_df = pd.DataFrame(links_rows) if links_rows else pd.DataFrame(columns=["From","Direction","Type","To"])
    return tree_df, links_df

# ========= Основной сценарий =========

def main():
    global EPIC_LINK_FIELD_ID, STORY_POINTS_FIELD_ID, RELEASE_NOTE_FIELD_ID_RESOLVED, SERVICE_FIELD_ID_RESOLVED

    print("=== Release Composer: старт ===")
    print(f"JIRA_URL               : {JIRA_URL}")
    print(f"PROJECT_KEY            : {PROJECT_KEY}")
    print(f"ONLY_UNRELEASED        : {ONLY_UNRELEASED}")
    print(f"VERSIONS_FILTER        : {', '.join(VERSIONS_FILTER) if VERSIONS_FILTER else '(все подходящие)'}")
    print(f"ENABLE_LINK_HIERARCHY  : {ENABLE_LINK_HIERARCHY}")
    print(f"CONFLUENCE_HOST        : {CONFLUENCE_HOST}")

    print("→ Получаю список версий...")
    versions = list_versions(PROJECT_KEY)
    if not versions:
        raise SystemExit("Нет подходящих версий (проверь фильтры/права)")

    # Определяем id кастом-полей
    ids = get_field_ids()
    EPIC_LINK_FIELD_ID = ids.get("epic_link")
    STORY_POINTS_FIELD_ID = ids.get("story_points")
    RELEASE_NOTE_FIELD_ID_RESOLVED = ids.get("release_note")
    SERVICE_FIELD_ID_RESOLVED = ids.get("service")
    if not EPIC_LINK_FIELD_ID:
        print("[warn] Не нашёл id 'Epic Link' — иерархия может быть неполной")
    # приоритет явных ID из ENV
    if RELEASE_NOTE_FIELD_ID:
        RELEASE_NOTE_FIELD_ID_RESOLVED = RELEASE_NOTE_FIELD_ID
    if SERVICE_FIELD_ID:
        SERVICE_FIELD_ID_RESOLVED = SERVICE_FIELD_ID

    # Поля для загрузки
    fields = [
        "summary", "issuetype", "status", "assignee", "parent",
        "subtasks", "issuelinks", "priority", "fixVersions", "created", "updated",
    ]
    if EPIC_LINK_FIELD_ID:
        fields.append(EPIC_LINK_FIELD_ID)
    if STORY_POINTS_FIELD_ID:
        fields.append(STORY_POINTS_FIELD_ID)
    if RELEASE_NOTE_FIELD_ID_RESOLVED:
        fields.append(RELEASE_NOTE_FIELD_ID_RESOLVED)
    if SERVICE_FIELD_ID_RESOLVED:
        fields.append(SERVICE_FIELD_ID_RESOLVED)

    per_release = []  # [(vname, tree_df, links_df, ov_df)]
    overview_rows: List[pd.DataFrame] = []

    for v in versions:
        vname = v.get("name")
        print(f"→ Версия: {vname}")
        jql = f'project={PROJECT_KEY} AND fixVersion="{vname}" ORDER BY issuetype, key'
        issues = jql_search(jql, fields, max_results=MAX_ISSUES)
        if not issues:
            print("  (нет задач)")
            continue

        # Сводка
        tmp = []
        for it in issues:
            f = it.get("fields", {})
            tmp.append({
                "Release": vname,
                "Тип": (f.get("issuetype") or {}).get("name"),
                "Статус": (f.get("status") or {}).get("name"),
                "Ключ": it.get("key"),
            })
        ov = pd.DataFrame(tmp)
        overview_rows.append(ov)

        # Иерархия
        tree_df, links_df = flatten_release_tree(vname, issues, EPIC_LINK_FIELD_ID)
        # Итоговые колонки для выдачи (Блок сразу после Level, Задача вместо «Ссылка», добавлена «Услуга»)
        tree_cols = [
            "Level", "Блок", "Услуга", "Краткое содержание", "Задача", "Артефакт", "Release Note",
            "Тип", "Статус", "Исполнитель", "Story Points", "Priority",
            "Fix Version(s)", "Created", "Updated"
        ]
        tree_df = tree_df[tree_cols]
        per_release.append((vname, tree_df, links_df, ov))

    if not per_release:
        raise SystemExit("Нет задач ни в одной из подходящих версий")

    writer_path = OUT_DIR / f"release_composer_{PROJECT_KEY}_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.xlsx"
    with pd.ExcelWriter(writer_path, engine="openpyxl") as xw:
        # Только Tree-вкладки по каждой версии
        for vname, tree_df, links_df, _ov in per_release:
            sheet_tree = make_sheet_name(vname, "Tree")
            tree_df.to_excel(xw, index=False, sheet_name=sheet_tree)
            ws: Worksheet = xw.sheets[sheet_tree]

            # Вставить легенду поверх заголовков
            insert_legend(ws, "Блоки: Развитие — голубой; Сопровождение — жёлтый")

            # Переустановить фильтр и закрепление с учётом легенды
            last_col_letter = get_column_letter(ws.max_column)
            ws.auto_filter.ref = f"A2:{last_col_letter}{ws.max_row}"
            ws.freeze_panes = "A3"  # легенда + заголовок

            # Уровни группировки строк по колонке Level (данные начинаются с 3-й строки)
            for df_idx in range(len(tree_df)):
                excel_row = 3 + df_idx  # 1: легенда, 2: заголовки
                try:
                    level_val = int(tree_df.iloc[df_idx]["Level"] or 0)
                except Exception:
                    level_val = 0
                ws.row_dimensions[excel_row].outlineLevel = level_val
                # автосворачивание: скрыть строки с уровнем > COLLAPSE_LEVEL
                if level_val > COLLAPSE_LEVEL:
                    ws.row_dimensions[excel_row].hidden = True

            ws.sheet_properties.outlinePr.summaryBelow = True
            ws.sheet_properties.outlinePr.applyStyles = True

            # Перенос строк и стили
            apply_wrap(ws, ["Краткое содержание", "Release Note"], header_row_idx=2)
            # Выровнять «Задача» по верхнему краю
            align_top(ws, ["Задача"], header_row_idx=2)
            apply_row_styles(ws, header_row_idx=2)

        # Сводная Overview (если нужна аналитика)
        if overview_rows:
            overview = pd.concat(overview_rows, ignore_index=True)
            pivot = pd.pivot_table(
                overview,
                index=["Release", "Тип"],
                columns=["Статус"],
                values="Ключ",
                aggfunc="count",
                fill_value=0,
                margins=True,
            )
            pivot.to_excel(xw, sheet_name="Overview")
            ws_ov: Worksheet = xw.sheets["Overview"]
            ws_ov.auto_filter.ref = ws_ov.dimensions
            ws_ov.freeze_panes = "A2"

    # Автофит ширины листов (понимает, что заголовок на строке 2)
    excel_autofit_smart(writer_path, width_overrides={
        "Блок": 16,
        "Услуга": 20,
        "Краткое содержание": 60,
        "Задача": 16,
        "Артефакт": 40,
        "Release Note": 50,
        "Исполнитель": 28,
        "Fix Version(s)": 28,
        "Priority": 12,
    })

    print(f"Готово → {writer_path}")

if __name__ == "__main__":
    # Поддержка запуска из консоли:
    # python Release.py CSHRM "Rel 2025.10"
    import sys
    if len(sys.argv) >= 2:
        pk = sys.argv[1].strip()
        if pk:
            PROJECT_KEY = pk
    if len(sys.argv) >= 3:
        VERSIONS_FILTER = [sys.argv[2].strip()]
    main()
